[{"title":"Serverless what? Why do we need it?","url":"/serverless-what-why-do-we-need-it/","content":"\n\"Serverless\" was one of those terms that left me scratching my head when I first heard it. How on earth do you run a server... without a server??? That's some crazy marketing spin! What I quickly learned is that serverless is referring to how much infrastructure you need to manage. That is, none. Nada.\n\nSo who cares? I mean, I'm running on PaaS. I can change the number of servers with a slider, or set rules to automatically add and remove servers as my traffic changes. Isn't that good enough? Not according to [Troy Hunt](https://www.troyhunt.com/serverless-to-the-max-doing-big-things-for-small-dollars-with-cloudflare-workers-and-azure-functions/). When your traffic spikes (like, when your site is on the news and a million people pick up their phone at the same time and hit your site), you can go from \"too much cloud\" to \"not enough cloud\" very quickly. It's in this environment of rapidly changing traffic (and realistically, that's when it counts), that serverless really shines.\n\n# So what is it?\nAlright, so what IS serverless? Let's consider what you might be using now. You've got a few VMs on a scale set, or you've got a few VMs as nodes of a Kubernetes cluster, or maybe you have some PaaS offering where you pick the number of machines backing it. You've got some rules in place to scale up as traffic increases and then back down to reduce costs when it falls again. Each of these scenarios have:\n* a fixed monthly costs per backing VM\n* a maximum traffic threshold\n* increasing latency as the traffic approaches the threshold\n* rules to increase and decrease the number of backing VMs to trade off running cost vs latency\n\nLet's say you increase your VMs by 10x or 100x. Assuming your architecture can scale, your latency issues have just vanished. Your servers are idling with unlimited resources compared to the current load. HOWEVER, your running costs have also increased by 10x or 100x. But the servers are just idling. So, what if you only paid for the activity you caused? That fraction of a ms of CPU. That couple of KB of RAM as you process an incoming request. Assuming the price is right, wouldn't that be better? Assuming the costs are around VM rate * Utilisation, you're instantly ahead! No more scaling of resources. Costs are directly related to resources used. Oh, and one final thing. The available resources is now a DATACENTER worth of resources. Your armageddon-style traffic spike is barely a blip on their radar.\n\nThat is Serverless.\n\n# How do I use it?\nUnfortunately, serverless doesn't necessarily come for free. Architecturally, you don't run your server any more. And I mean software server, not the VM. Instead, you need to present a function based API (eg. Azure Functions or AWS Lambda) and that is effectively injected into the provider's service to execute  as configured. If you have followed a [Clean Code Architecture](https://youtu.be/_lwCVE_XgqI?list=PL7soaAB-BQAbAFa1XZkg7wOvDHorQ7KiO), it's probably simple to extract your application logic into a Functions application. If you've got application code in your controllers, or using Filters, etc, well, that will take more.\n\nSome services are Serverless already and some are not. If you want to build serverless, you're looking at:\n* Storage\n* Azure Functions\n* Service Bus\n* SignalR service\n* AKS (with virtual kubelet)\n\nIf you want to bring your serverless architecture to its knees, try:\n* SQL Server (for now - [serverless is coming](https://docs.microsoft.com/en-us/azure/sql-database/sql-database-serverless))\n* Web apps\n\nI've had a hard time putting AKS in either bucket at the moment. It runs on specific nodes (so not serverless), but there's also a virtual Kubelet that lets you use ACI as a serverless overflow. Personally, I prefer the Azure Function pricing model over the ACI pricing model and the cost of spinning up a function is MUCH lower than spinning up a container, however it might keep up if your site had a massive traffic spike. Probably somewhere between \"pure\" serverless and PaaS, but this is just a guess. So, it may be possible to use containers, AKS and Virtual Kubelet to take you some of the way towards stability within rapid traffic spikes, depending on your service startup time.\n\n# Final words\nServerless brings an extraordinary level of burst tolerance to your application, which will bring resilience and performance under extreme loads. As with any architectural decision, it's not all or nothing. You can have parts of a system that are serverless, with other parts not, such as a Web App that sends messages to a Service Bus. With a serverless backing, the web app will likely provide greater resilience under load. Use load testing to measure where your bottlenecks are. Importantly, look for any part of your architecture where serverless is hitting resource bound components. Make sure you have a fallback strategy for when the resource bound component is at maximum load.\n\nServerless is actually not a new idea and there are many serverless services available. Please refer to the [Azure Serverless services](https://azure.microsoft.com/en-us/solutions/serverless/) for more info. Effective use of serverless components in your architecture will massively increase the scalability of your application.\n"},{"title":"So... Cloudflare...","url":"/so-cloudflare/","content":"\nI went to a great talk by Troy Hunt in Brisbane a while ago. Well, it was great at the time. It didn't take long before I started to realise that most of the struggles I've had with HTTPS my blog could have actually been side stepped quite nicely by using [Cloudflare](https://www.cloudflare.com/).\n\nLet me be clear. This wasn't the first time I heard of Cloudflare. To be honest, I didn't actually know what it was before now though, and Troy has a way of presenting things so that they seem really quite simple. Cloudflare seems to provide a service that just puts a bow on hosted services: Free SSL, CDN/caching, DNS, traffic management. Cloudflare aim to have an edge within 10ms of every client on the planet.\n\nSince I already had my HTTPS sorted, I didn't worry too much about it at the time. Now, I'm looking for CDN and it wouldn't hurt to have an overlay on my site that allows some modifications to requests and responses (like HTTP/2, which Cloudflare seem to enable by default).\n\nGetting set up is easy enough.\n1. Create an account with [Cloudflare](https://www.cloudflare.com/).\n2. Add a site (eg. anthonyison.com).\n3. Set up the DNS servers with your domain provider.\n4. Add an A record to cloudflare to point to your IP (eg. for AKS) or CNAME to redirect to your alternate domain (eg. GitHub pages or web app)\n5. Wait for the change to take effect. This can take up to 48 hours.\n\nOnce CDN is in place, we've got one small problem. When we change the content, we need to be able to purge the cache. Cloudflare provides an API for achieving this. We just need to add it to the build pipeline. One way of doing it would be to create a Logic App that punches the API whenever there's a new commit on the github pages repo.\n\nI might do that later on...\n\nFor now, I've hosted both blogs, just for comparison. I'm running [Lighthouse](https://developers.google.com/web/tools/lighthouse/) against both to see if there's much of a difference.\n\nRunning Ghost:\n![Ghost Summary](/so-cloudflare/ghost_summary.png)\n![Ghost Performance](/so-cloudflare/ghost_performance.png)\n\nRunning Hexo on Github Pages:\n![Ghost Summary](/so-cloudflare/github_summary.png)\n![Ghost Performance](/so-cloudflare/github_performance.png)\n\nRunning Hexo on Github Pages behind Cloudflare:\n![Ghost Summary](/so-cloudflare/cloudflare_summary.png)\n![Ghost Performance](/so-cloudflare/cloudflare_performance.png)\n\n\nWith Cloudflare in place, I have CDN, HTTPS, HTTP/2 in place. I've enable Rocket Loader to improve paint time and auto-minify so that I can pull that from my build process. I can enable HSTS automatically, but not sure it's necessary?\n\nFor now, I think the numbers are heading in the right direction, even though I seem to have introduced a couple of new issues while migrating to hexo.","tags":["CDN"]},{"title":"Migrating from Ghost to Hexo","url":"/migrating-from-ghost-to-hexo/","content":"It was surprisingly easy to migrate my blog out of ghost, but there were a few missed steps along the way. Often, I would find a better way after I had done the heavy lifting.\n\n## 1. Install Hexo and create the blog\n```\n$ npm install hexo-cli -g\n$ hexo init myblog\n$ cd myblog\n```\n\n## 2. Install the hexo-casper theme\n```\n$ git clone https://github.com/xzhih/hexo-theme-casper.git themes/hexo-casper\n```\n\n## 3. Configure the theme and site\nEdit _config.yaml\n```yaml\n# Site\ntitle: Anthony Ison\nsubtitle: Software development and DevOps. Bringing solutions to life.\ndescription: My meandering thoughts on development, devops and technology\nkeywords: software development,devops,azure,kubernetes,angular,serverless,docker\nauthor: Anthony Ison\nlanguage: en\ntimezone: Australia/Brisbane  # From http://momentjs.com/timezone/\nurl: http://anthonyison.com\nroot: /\n\n# Set these to create lowercase, title-only permalinks (like ghost)\npermalink: :title/\nfilename_case: 1\n\n# consider creating a folder with each post to hold any assets\npost_asset_folder: true\n```\n\nEdit themes/hexo-casper/_config.yaml\n\n## 4. Migrate posts from ghost to hexo\nIn Ghost:\nLabs > Export content\n\n```\n$ npm install hexo-migrator-ghost --save\n$ hexo migrate ghost my-ghost.json\n```\n*FAILED!*\n\n```\n$ npm install hexo-migrator-tryghost --save\n$ hexo migrate ghost my-ghost.json\n```\n*FAILED!*\n\nThese probably failed because I was running Ghost 2.x and the export format has changed. If you've got an earlier version, maybe this will work for you.\n\n```\n$ docker run -it -v $(pwd):/temp golang\n$ go get -v github.com/jqs7/ghost-hexo-migrator\n$ cd /temp\n$ ghost-hexo-migrator my-ghost.json\n```\n*FAILED!*\n\nThis got a little closer, and actually pulled content across, but now I'm out of options. Fortunately, I don't have many posts and will manually migrate instead. I hope you have better luck.\n\n## 5. Reattach the post images\nMany of the migration tools will bring content across without images. So afterwards, you will need to copy the images in and link them to posts manually.\n\nAlso, it's worth configuring an image optimizer, using:\n```\n$ npm i hexo-filter-responsive-images --save\n```\n\nThen add to the _config.yaml:\n```yaml\n# hexo-filter-responsive-images\nresponsive_images:\n  pattern: '**/*.+(png|jpg|jpeg)'\n  sizes:\n    small:\n      width: 800\n      withoutEnlargement: true\n    large:\n      width: 2000\n      withoutEnlargement: true\n```\n\nTo each of the blog post headers, add:\n```yaml\ncover_img: my-blog-post/small_cover.jpg\nfeature_img: large_cover.jpg\n```\nwhere cover.jpg is the original image for the post cover.\n\n## 6. Configure RSS\n```\n$ npm install hexo-generator-feed --save\n```\n\nAdd this to your _config.yaml:\n```yaml\nfeed:\n  type: atom\n  path: atom.xml\n  limit: 20\n  hub:\n  content:\n  content_limit: 140\n  content_limit_delim: ' '\n  order_by: -date\n  icon: icon.png\n```\n\n## 7. Configure deploy\n```\n$ npm install hexo-deployer-git --save\n```\n\nEdit _config.yaml\n```yaml\ndeploy:\n  type: git\n  repo: https://github.com/isonaj/isonaj.github.io.git\n  branch: master\n```\n\n","tags":["ghost","hexo","blogging"]},{"title":"Serverless markdown blogs with Hexo","url":"/serverless-markdown-blogs-with-hexo/","content":"Let me start this by saying I'm loving my ghost blog, and I get a kick out of running it on AKS. The thing is, the content only changes when I post and so I'm thinking about caching and I realise the whole blog can be cached. It's not an API. I don't have changing data. (Ok, TECHNICALLY I have a db, but bear with me) My posts are markdown, and I could just store them in git and publish static pages when I push.\n\nAfter some searching, I have found there are many static web site generators. The ones that stood out for me were: \n* [Jekyll](https://jekyllrb.com/) - this is number 1 and the default in [Github Pages](https://pages.github.com/). It runs on Ruby.\n* [Hexo](https://hexo.io/) - this is huge in China and built on node\n* [Vuepress](https://vuepress.vuejs.org/) - built for Vue docs. I think I will love this when the project is a bit more mature.\n\n> I thought I'd review Jekyll and Hexo, so I pulled a jekyll container in one window and installed Hexo in another. Unfortunately, I was up and running with Hexo before my download even finished, so rather than having a post that contrasts the two, I seem to have already chosen Hexo.\n\n# Jekyll\nThis is far and away the most popular. It has a thiving community and is well supported by Github Pages. The main disadvantage is that it becomes exponentially slower as pages are added, which wouldn't likely be an issue for my blog but is worth noting.\n\n# Hexo\nHexo is number 2 in popularity (mostly in China) and is growing fast. It also has many themes, and most of the demo sites are in Chinese.\n\n## Installing Hexo\nSince it's built on node, Hexo is super easy to install (assuming you already have node installed!) We will be using npm to install.\n\n```\n// Install Hexo:\nnpm install hexo-cli -g\n\n// Create a site:\nhexo init my-site\n\n// Create a post:\nhexo new post \"This is going to be a great post\"\n\n// Serve your site locally:\nhexo serve\n\n// Generate the static site:\nhexo generate\n```\n\nYou can also:\n* Create a draft with `hexo new draft \"This is a draft post\"`\n* Publish a draft with `hexo publish post this-is-a-draft-post`\n* Deploy your site: `hexo deploy`\n\n## Themes\nThere are many themes around. Usually, you pull a git repo into your themes/theme-name folder. Themes basically wrap the whole presentation process, which means each theme has specific capabilities. (eg. some have google analytics, some have disqus comments). If you want to mix and match, you quickly find yourself editing your theme.\n\n## Plugins\nThere are different types of plugins. They seem to hook into the build process and provide various services. I haven't looked into them too much yet.\n\n## Migrators\nThere are migrators available and you can pull them in with npm install. I quickly found migrators for Wordpress and Ghost blogs. \n\n# Summary\nHexo is node-based and provides a familiar interface for an Angular developer. It is a fantasic tool for getting a blog up and running and has capability to migrate from existing platforms. Since it is git based, it's a bit harder to manage from my phone, however I LOVE that my markdown content is in git so I can review changes and I know it won't be lost in a corrupt database.\n\nWhat do you think? Would you use Hexo?","tags":["hexo"]},{"title":"Dynamic environment in your static Angular application","url":"/dynamic-environment-in-your-static-angular-application/","content":"I keep hitting the same problem when building Angular applications. Environment settings! They are easy to set up in development, but as you target different environments, the old \"one file per environment\" really doesn't cut it. I don't want to rebuild my application just to deploy to production and if it's in a container? Pfft, good luck! I've solved this problem a few different ways in the past and I've just solved it again. But this time, it didn't feel quite so hacky, so I thought I'd post about it.\n\n## Problem\nAngular CLI provides an `environment.ts` for storing your global settings and you can select which environment file to use when you build. I want to build my application once and then deploy to different environments without rebuilding, however I can't change my environment settings on deploy or through environment variables. There are a few reasons I don't want to rebuild.\n1. I want to test in staging and then redeploy the artifact to production\n2. I want to run it from a container\n\n## Solution\nOk, so this is not a new problem and it has been reasonably solved on server side deployments a few ways:\n1. Environment variables / web.config / appsettings.json - config is easily overridden in place and is often used for server config settings.\n2. Rewrite on deploy - the deployment script itself can overwrite settings as it is deployed to configure the environment it is deploying to.\n\n### Option 1: Inject bootstrap settings into the index.html\nThis was my first attempt at solving the problem. I added a comment in the index.html and created an MVC endpoint to load the index.html file, replace the comment with a script block to create a settings object and return the updated html page. It was good for keeping the number of requests down, but it felt a bit hacky.\n\n### Option 2: A separate bootstrap script file\nThis approach was inspired by [this post](https://www.jvandemo.com/how-to-configure-your-angularjs-application-using-environment-variables/). The basic idea is to pull a separate self-executing script that contains our bootstrap settings from the `index.html`.\n\n```markup\n<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <title>My Awesome Angular app</title>\n    <base href=\"/\">\n    <meta name=\"viewport\" \n          content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n    <!-- Load environment variables -->\n    <script src=\"assets/bootstrap.js\"></script>  \n  </head>\n  <body>\n    <app-root></app-root>\n  </body>\n</html>\n```\n\nNext, create the `bootstrap.js` file in your assets folder. It should look something like this:\n```javascript\n(function (window) {\n  window.bootstrapSettings = {\n    apiUrl: 'https://localhost:44384',\n    production: false,\n  };\n}(this));\n```\n\nWhen the angular app loads, we now have a bootstrap object available to pull settings from. In this case, I can reference `window.bootstrapSettings.apiUrl` to find my api location, but I'm trying to use `environment.apiUrl`.\n\nNext, we need to update `environment.ts` to bring in the bootstrap settings.\n\n```typescript\nexport const environment = Object.assign({\n    production: false,\n  },\n  (window as any).bootstrapSettings);\n```\n\nAt this point, we can build once and serve from different static sites by simply applying a different `assets/bootstrap.js` file with the new settings during deployment.\n\nThis is good, but we're serving from dotnet core, so we can do better. (If you're using node, the idea is not much different). The basic idea is to avoid serving the static bootstrap file and instead, send a bootstrap file based on our appsettings file, which we can easily override from our environment (web app, container, etc) using the middleware below.\n\n```csharp\npublic class EnvironmentBootstrap\n{\n    public string apiUrl { get; set; }\n}\n\npublic static class EnvironmentBootstrapExtensions\n{\n    public static IApplicationBuilder UseEnvironmentBootstrap(\n\t\tthis IApplicationBuilder builder, string path)\n    {\n        return builder.UseMiddleware<EnvironmentBootstrapMiddleware>(path);\n    }\n}\n\npublic class EnvironmentBootstrapMiddleware\n{\n    private readonly RequestDelegate _next;\n    private readonly EnvironmentBootstrap _environment;\n    private readonly string _endpointPath;\n\n    public EnvironmentBootstrapMiddleware(\n    \tRequestDelegate next, \n        IOptions<EnvironmentBootstrap> options, \n        string path)\n    {\n        _next = next;\n        _endpointPath = path;\n        _environment = options.Value;\n    }\n\n    public async Task Invoke(HttpContext httpContext)\n    {\n        // Short circuit on request for bootstrap.js\n        if (httpContext.Request.Path\n            .Equals(_endpointPath, StringComparison.Ordinal))\n        {\n            httpContext.Response.ContentType = \"application/javascript\";\n            await httpContext.Response.WriteAsync(\n            \t\"(function (window) { window.bootstrapSettings = \" +\n            \tJsonConvert.SerializeObject(_environment) + \n            \t\";}(this));\");\n        }\n        else\n            // Pass to next item in the pipeline\n            await _next.Invoke(httpContext);\n    }\n}\n```\n\nFinally, activate the pipeline in the Startup.cs file:\n```csharp\npublic class Startup\n{\n    public void ConfigureServices(IServiceCollection services)\n    {\n        // ...\n        services.Configure<EnvironmentBootstrap>(\n            Configuration.GetSection(\"client\"));\n        // ...\n    }\n                    \n    public void Configure(IApplicationBuilder app)\n    {\n        // ...\n        // Bootstrap the bootstrap.js file ahead of UseStaticFiles\n        app.UseEnvironmentBootstrap(\"/assets/bootstrap.js\");\n        app.UseStaticFiles();\n        app.UseSpaStaticFiles();\n        // ...\n    }\n}\n```\n\nThat's it! The project can now be built once and deployed to different environments, with angular client environment settings available to be configured from the environment itself. For an Azure Web app, set an Application Setting 'client:apiUrl' to override the client's `apiUrl` environment setting.\n\nWhat do you think? Is there a better solution? What do you like or dislike about this approach?","tags":["dotnet","angular"]},{"title":"Automatic HTTPS on Kubernetes","url":"/automatic-https-on-kubernetes/","content":"This post starts with a slight regret that I didn't get Ghost running on a Web App.  One of the brilliant parts of a Web App is that you can force all requests over HTTPS with the click of a button. Of course, I'd still need to organise a certificate for my domain. Hold on, let me stop and back up a minute.\n\nWhat the heck is this HTTPS and certificate stuff? Basically, HTTPS will guarantee that the communication between the client and server can't be read or changed by anyone between the client and server. So, usernames and passwords are safe to send. While that's important, it's probably more important that your pages cannot be changed either. It's a bit like a message written in code with the king's seal. Since the code (HTTPS) is known to you and the king, you know it cannot be read. The seal (certificate) proves the authenticity.\n\nAs I set out on this adventure, it looks like I need cert-manager and the best way to install this appears to be to use helm, which I installed with Chocolatey.\n\n```\nchoco install kubernetes-helm\nhelm init\n```\n\n## First steps\nWe are going to install cert-manager which will perform all of the magic of fetching certificates and storing them for use in our various services. We need to set up the config for cert-manager, so that we can provide the link to Lets Encrypt. Save the following in a file, say issuer.yaml, and run `kubectl apply -f issuer.yaml` to apply. (Make sure you update with your email first!)\n\n```yaml\napiVersion: certmanager.k8s.io/v1alpha1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory    \n    email: youremail@gmail.com\n    privateKeySecretRef:\n      name: letsencrypt-prod\n    http01: {}\n```\n\n## Installing cert manager\n```\nkubectl apply -f \\\n    https://raw.githubusercontent.com/jetstack/cert-manager/release-0.6/deploy/manifests/00-crds.yaml\n\nhelm install --name cert-manager --namespace ingress \\\n    --set ingressShim.defaultIssuerName=letsencrypt-prod \n    --set ingressShim.defaultIssuerKind=ClusterIssuer \n    stable/cert-manager\n```\n\nI ran into issues installing cert-manager with a 'cluster-admin' not found error. I found instructions on [this page](https://docs.bitnami.com/azure/get-started-aks/) which helped me create a cluster admin role, create a service account and assign tiller to it.\n\n## Installing nginx-ingress\nThe next step is to configure an Ingress to manage the TLS endpoint, that is to manage my HTTPS endpoint with certificate connected to my domain. Without this step, I found I could set up my Ingress entry, but the address would stay empty.\n\n```\nhelm install stable/nginx-ingress \\\n    --name nginx \\\n    --set rbac.create=true \\\n    --namespace ingress\n```\n\nOnce installed, I can see a LoadBalancer entry which has my External IP on it.\n\n## Update the Service\nIn the previous post, we set the service up as a LoadBalancer type. We don't need that any more since we have a new IP on our LoadBalancer nginx-ingress service. Update the service.yaml and change LoadBalancer to a NodePort and run `kubectl apply -f service.yaml`. This will make sure we can only access our service through our TLS ingress service.\n\n## Generate Certificate and Ingress for Service\nApply the following updates to the kubernetes cluster.\n\n```yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: anthonyison-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    certmanager.k8s.io/cluster-issuer: letsencrypt-prod\nspec:\n  tls:\n  - hosts:\n    - anthonyison.com\n    secretName: anthonyison-crt\n  rules:\n  - host: anthonyison.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: anthonyison\n          servicePort: 80\n```\n\n```yaml\napiVersion: certmanager.k8s.io/v1alpha1\nkind: Certificate\nmetadata:\n  name: anthonyison-crt\nspec:\n  secretName: anthonyison-crt\n  dnsNames:\n  - anthonyison.com\n  acme:\n    config:\n    - http01:\n        ingressClass: nginx\n      domains:\n      - anthonyison.com\n  issuerRef:\n    name: letsencrypt-prod\n    kind: ClusterIssuer\n```\n\nThat's it!  Hit your domain and confirm that https is working. You should be able to click on the padlock in the address bar and click on Certificate to see the details. You should see a certificate issued by Lets Encrypt to your domain name.\n\nSo, I started off with some regret that I wasn't running in a Web App. While it took quite a while to work through many of the issues that showed up along the way, it is actually pretty easy once it's set up, and furthermore, I don't have to think about my certificates ever again. I think maybe it's not as bad as I thought. No regrets, right?\n\n### References:\n1. [Automated TLS with Cert Manager and Lets Encrypt for Kubernetes](https://itnext.io/automated-tls-with-cert-manager-and-letsencrypt-for-kubernetes-7daaa5e0cae4)\n2. [Get automatic HTTPS with Lets Encrpyt and Kubernetes Ingress](https://akomljen.com/get-automatic-https-with-lets-encrypt-and-kubernetes-ingress/)\n3. [How to use Lets Encrypt on Kubernetes (without Cert Manager)](https://runnable.com/blog/how-to-use-lets-encrypt-on-kubernetes)\n4. [Configuring AKS](https://docs.bitnami.com/azure/get-started-aks/)\n5. [Secure your Kubernetes Services using Cert Manager](https://dzone.com/articles/secure-your-kubernetes-services-using-cert-manager)","tags":["kubernetes"]},{"title":"Running Ghost on Kubernetes on Azure","url":"/running-ghost-on-kubernetes-on-azure/","content":"In my [previous post](/creating-a-blog-with-ghost/), I was looking into a few options for running my blog. I think at this time, I'm going to keep it on Azure because I can run it for free. I suspect I would make a different choice if not for my bonus credits. I will need some benchmark figures to choose a provider, however kubernetes should give me the platform I need to change in the future if necessary.\n\nI have a basic level of understanding of how kubernetes hangs together and would love to hear your feedback if you would do things differently. The basic idea is to run a ghost container and provide persistent storage for the content. In the future, I would like to use nginx to reverse proxy incoming traffic and to provide HTTPS for my site.\n\nI have used AKS to generate a kubernetes cluster and my kubectl is configured to connect to it. First, I need to configure my storage. For this, I use a yaml file.\n\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: anthonyison-content\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: default\n```\n\nUsing `kubectl apply -f volume.yaml` we can generate the volume claim to be used in the next step. Next, we will generate a deployment for the the ghost container, linking it to the anthonyison-content volume.\n\n```yaml\napiVersion: apps/v1beta1\nkind: Deployment\nmetadata:\n  name: anthonyison\n  labels:\n    app: anthonyison\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: anthonyison\n  template:\n    metadata:\n      labels:\n        app: anthonyison\n    spec:\n      containers:\n      - name: anthonyison\n        image: ghost:2.9.1-alpine\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 2368\n        env:\n        - name: url\n          value: http://anthonyison.com\n        volumeMounts:\n        - mountPath: /var/lib/ghost/content\n          name: content\n      volumes:\n      - name: content\n        persistentVolumeClaim:\n          claimName: anthonyison-content\n```\n\nSo now we have a ghost container running in Kubernetes with an external mounted volume for storing content. However, it's not exposed as yet. We do that with a Service. The `service.yaml` is below.\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: anthonyison\nspec:\n  type: LoadBalancer\n  selector:\n    app: anthonyison\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 2368\n```\n\nAnd that's actually all there is to it. By running `kubectl get services` you can see the External IP. If you put that in the browser, you will go to the new blog. Better still, put the IP into your DNS A record, and your domain name will direct to the new site.","tags":["kubernetes","ghost","azure"]},{"title":"Creating a blog with Ghost","url":"/creating-a-blog-with-ghost/","content":"There seems to come a time in a software developer's life where you look at creating a blog. It's that time for me. I want a place where I can write up some of my experiments for later reference, and if that can help others along the way, all the better!\n\n## Considerations\n1. I don't want to pay anything. I really don't want to break the bank with this project. If I can pay nothing, I will. This puts [Azure](https://azure.com) squarely in the front seat because I have $70 a month to spend there.\n2. Easy to use. I don't want to spend ages messing with this project, or debugging issues.\n3. Broad application / reusable. It would be great if this thing can be used for more than just this blog. If I can host other sites or blogs on the same infrastructure, that would be kinda handy.\n4. Preferably something I want to learn. Cause, you know. What's the point otherwise?\n\nAt first, I had thought I'd be using [Wordpress](https://wordpress.org) and I wasn't really looking forward to that. On the upside, there are wordpress containers around and I was pretty keen to run it in a container.\n\nAfter a quick email with [Thiago](https://passos.com.au), I started looking at [Ghost](https://ghost.org). Once I knew it was there, I noticed that many of the blogs I read, including [Troy Hunt](https://www.troyhunt.com), are powered by Ghost. With little more than that meagre planning, it was time to get started.\n## Attempt 1: Azure Web apps\nFirstly, I needed a place to host it. I'm an Azure guy, so I started there. It seemed to be straight forward enough. A ghost container, wrapped in a Web App, running on Linux, volume mapped to a Azure File storage. I ran it locally and it worked perfectly. Once installed on Azure, I found the database just wouldn't load up correctly, giving Migration errors, saying that the database was locked.\n\nFirst attempt foiled!\n## Attempt 2: Google GKE\nMy next attempt was to spin it up on GKE on to [Google cloud](https://cloud.google.com). [Kubernetes](https://kubernetes.io) seemed to be a bit of overkill for what I was trying, but Google made that super easy, and it pretty much \"just worked\".\n\nThat left me with the question, what about AKS on Azure?\n## Attempt 3: Azure AKS\nI've never created an AKS cluster. I mean, I've wanted to. Who hasn't? The thing is, I've never actually clicked the Go button. So, I guess it's time. It was easy enough to configure as well and then I clicked Create and waited. I waited and then I waited some more. I went looking for any events showing that something was happening, but couldn't see anything. So I tried again and this time, it worked.\n\nIt spun up easy enough and with minor changes to the PersistentVolumeClaim, it just worked as well, albeit it a bit slower than GKE, which was odd because I had double the resources on Azure.\n## So, now what?\nAlright, so now I seem to be on the kubernetes train. Even writing it now, it seems kinda crazy to spin up a kubernetes cluster to run a blog that is probably only going to have me as traffic. But it is expandable. There are a couple of sites I want to host. They're currently in containers on Azure Web apps, but should move across easy enough.\n\nI'm still not sure of cost. I will run both solutions for a couple of days and have a look at what charges come through. I hadn't planned to move from Azure at this time. That's where I have the most experience.\n## Next steps\n1. Run some performance and pricing measures to compare GKE vs AKS and decide where my blog will stay.\n2. Write up the technical steps for creating the blog.\n3. Enable the site to run [HTTPS](https://www.troyhunt.com/the-6-step-happy-path-to-https/) with [Let's Encrypt](https://letsencrypt.org) certificates.","tags":["ghost"]}]