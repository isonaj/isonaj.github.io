[{"title":"Refactoring code - restructure, not rewrite","url":"/refactoring-code-restructure-not-rewrite/","content":"\nI see a lot of similarities between software and business processes. If I'm talking about a queuing mechanism, it often helps to describe it as a call centre managing their tickets, or a lock as being like a key for the toilets. Refactoring then, would simply be a restructuring of a business or to give someone a new title or change teams around, however software developers often use it to mean they want to fire everyone and start over.\n\nWhen we compare software processes and business processes, it can make it easy to communicate the benefits or drawbacks of a particular solution. Furthermore, when the stakeholders are engaged in the conversation **and they understand what's being discussed** they can guide the process more easily and it becomes a win-win for the software developers and the business. But I digress... \n\nLet's get back to the dreaded **rewrite**. It's always possible that a business is in a state where this is needed, however small changes to a working system can produce incredible results. Software is expensive. I mean, REALLY expensive. So, let's not burn down the house just because we no longer like the decor.\n\nAs a software developer, refactoring is one of your daily chores. The thing about a daily chore is that, when it's not done, it kind of builds up. If you never do your chores, you might find that you have a BIG job to get things neat and tidy again. And then, even if you stay on top of your chores, you might find you need a spring clean now and then just to get to the areas that aren't being kept daily.\n\n> The word \"refactoring\" should never appear in a schedule. Refactoring is not a story or a backlog item. Refactoring is not a scheduled task. Refactoring is immediate and continuous. It's like washing your hands in the bathroom. You always do it. - [Uncle Bob Martin](https://twitter.com/unclebobmartin/status/1024254121338126336)\n\nThe problem is, software developers don't seem to agree on what refactoring is. It is often used to mean fixing a bug by writing \"clean code\" (or code that introduces design patterns) instead of \"messy code\". That's not refactoring though, and as a community, we need to understand what refactoring is.\n\n## So what is it?\n\n> I've never seen one before. No one has, but I'm guessing it's a white hole - [Kryten](https://www.youtube.com/watch?v=TxWN8AhNER0)\n\nRefactoring is a change made to the internal structure of **existing software** to make it **easier to understand** and cheaper to modify **without changing its observable behaviour**. It does not mean \"cleaning up code\". Basically, if you are fixing an issue or adding new behaviour, you are NOT refactoring. It is often an iterative, mechanical process that is practically risk-free. How can it be risk-free? Well, the types of changes we are talking about are renaming methods or variables or extracting a small chunk of code from one method into another.\n\n> WARNING: I'm about to show an example of refactoring some code. If you're not a software developer, focus on the difference between the starting code and the finished product.\n\nConsider the following example:\n```csharp\n// ...\nvar t = this.Items.Sum(i => i.Qty * i.Price);\nt -= Math.Round(this.Discount * t, 2);\nvar tt = Math.Round(t / 11, 2);\n// ...\n```\n\nThere are a few issues with this example. Let's fix some of the variables.\n```csharp\nvar subtotal = this.Items.Sum(i => i.Qty * i.Price);\nvar discount = Math.Round(this.Discount * subtotal, 2);\nvar total = subtotal - discount;\nvar gst = Math.Round(total / 11, 2);\n```\n\nThere is a code smell here with the parent accessing the child data (Qty and Price) to calculate the item subtotal. I think my first step here would be to add a get property to the child class to handle this.\n```csharp\nvar subtotal = this.Items.Sum(i => i.Subtotal);\nvar discount = Math.Round(this.Discount * subtotal, 2);\nvar total = subtotal - discount;\nvar gst = Math.Round(total / 11, 2);\n```\n\nFinally, the tax calculation has a hardcoded tax rate and it's not clear that this is calculating Gst, so let's move it to a global Gst calculator. I'm also not sure how often Gst is calculated, but this provides a single location to update all Gst calculation in the case that the rate changes.\n```csharp\nvar subtotal = this.Items.Sum(i => i.Subtotal);\nvar discount = Math.Round(this.Discount * subtotal, 2);\nvar total = subtotal - discount;\nvar gst = GstCalculator.CalculateTax(total);\n```\n\nAs you can see, the refactored code should produce the same results as the original code and has significant improvements to readability, mostly from renaming variables. It may not be immediately obvious that the extra context from naming helps to document the code without adding comments.\n\n## Refactoring Techniques\nI mentioned earlier that refactoring is a mechanical process. In fact, there are lists of known [refactoring techniques](https://refactoring.guru/refactoring/techniques), the most well-known being Martin Fowler's [catalog](https://refactoring.com/catalog/). Be aware that for every refactoring, there is an equal and opposite refactoring. There is not really a \"best way\" to layout your code. Instead, you need to choose a refactoring that \"improves\" your code. If the code is overly complex, you might be looking at refactorings that reduce complexity. Alternatively, you might increase complexity to gain flexibility.\n\n> Refactoring is a disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behaviour - [Martin Fowler](https://refactoring.com/)\n\nThe main benefits of refactoring are increased maintainability and extensibility with a low risk of introducing new issues. Like [Test Driven Development](https://en.wikipedia.org/wiki/Test-driven_development) (TDD), refactoring requires discipline to gain the full benefit from the practice. While each change seems too small to bother with, the cumulative effect of the practice will transform your code. \n\nIf you want to learn more about refactoring techniques, I highly recommend the book, [Refactoring: Improving the Design of Existing Code](https://martinfowler.com/books/refactoring.html). Originally published in 1999, it's recently had a 2nd edition.\n\nThe idea of refactoring has been around for a long time and seems to be largely misunderstood by the software development community. By consistently refactoring before writing new code, software developers are able to improve the code base and improve maintainability and extensibility even to legacy applications.\n","tags":["principles"]},{"title":"Static Site Generation with Vuepress","url":"/static-site-generation-with-vuepress/","content":"When I was reviewing static site generators, [Vuepress](https://vuepress.vuejs.org/) caught my eye but I passed over it quickly because their web site admitted that they [lacked blogging support](https://vuepress.vuejs.org/guide/#todo). I really liked the approach though. It uses the [Vue.js](https://vuejs.org/) server-side processing to generate static sites. It's time to have a closer look.\n\n> **UPDATE 2019-07-18:** \"Vuepress lacks blogging support\" is no longer accurate. Vuepress has added A LOT of features in [version 1.0](https://medium.com/@_ulivz/intro-to-vuepress-1-x-7e2b7885f95f) that addresses the issues I experienced while writing this post. Stay tuned for another post on Vuepress soon!\n\n## Creating content\nMy first measure of a tool is how easy it is to get started. For Vuepress, that means I want to create a couple of posts. It's really easy to create some quick content, like so:\n```bash\n# Create a folder for the blog\n$ mkdir myblog\n$ cd myblog\n\n# Create a package.json file and add vuepress\n$ npm init    # Enter through to accept all defaults\n$ npm i vuepress --save\n```\nCreate the following files:\n**post1.md:**\n```markdown\n# My first post\nHere is some content\n```\n\n**post2.md:**\n```markdown\n# My second post\nHere is some more content\n```\n\n**index.md:**\n```markdown\n# Index\n* [First post](/post1.md)\n* [Second post](/post2.md)\n```\n\nNext, we need to configure npm to run vuepress for us. Edit the newly created `package.json` file in the current folder and change the scripts section to:\n```js\n  \"scripts\": {\n    \"dev\": \"vuepress dev\",\n    \"build\": \"vuepress build\"\n  },\n```\nYou can now run `npm run dev` to serve your blog.\n\nOk, so it wasn't THAT easy to get started. I would really prefer to see some kind of init stage here instead, but it's not too bad and you only have to get set up once. I'm guessing these concerns would be addressed if/when they add blogging support. \n\nLooking at the new site, it's pretty barebones but it already has a search box that can look up my posts by title, so there's that. What we have at this point is basically a wiki page. While that's ok, I actually just want to create blog posts. I don't want to have to build links from my main page to each post.\n\nLet's take a look at themes.\n\n## Adding a theme\nVuepress provides a clear separation between the content and the theme. The theme pieces will all live in the `.vuepress` folder. That is, any site configuration, layouts, components, etc can be found in this folder. Let's try out some of this now.\n\n### Configuration\nCreate the `.vuepress` folder and add a `config.js` file with the following:\n```js\nmodule.exports = {\n  title: 'My Vuepress Blog',\n  description: 'Taking Vuepress for a spin'\n}\n```\n\n### Default Layout\nYou can easily export the starting default theme by running `npx vuepress extract`. This will save the default layout in the `.vuepress\\theme` folder. I'm not going to open up themes too much just yet. That would be a whole blog post to itself, but if you're interested in digging in, I recommend [this post](https://www.amie-chen.com/blog/20190211-build-a-site-with-vuepress-part2.html).\n\n![Vuepress site with default layout](screenshot1.png)\n**Figure: Vuepress site with default layout**\n\n## Downloading a theme\nIf you're like me, you're not interested in the absolute nitty-gritty of the theme. You just want to generate content. What I like about Vuepress is that the theme is Vue.js and I can have a good crack at trying to maintain my theme, or tweak the theme as needed.\n\nAs you can see in my blog, I am captivated by the Casper theme and fortunately, Vuepress has a Casper theme [here](https://github.com/alexander-heimbuch/vuepress-theme-casper). In my mind though, this theme leaves a lot to be desired when compared to my current (tweaked) hexo casper theme. This one requires the reading time to be added to the frontmatter, but that could possibly be automated with [this plugin](https://github.com/darrenjennings/vuepress-plugin-reading-time).\n\n![Vuepress site with Casper layout](screenshot2.png)\n**Figure: Vuepress site with Casper layout**\n\n## Blogging support\nIn [this post](/blogging-for-consistency), I looked at some of the expectations for a blog. Let's take a look at which parts we can hit with Vuepress.\n\n### Comments\nI use Disqus for comments. It uses JS to plugin to your page so should be able to run pretty much anywhere.\n\n### RSS\nVuepress has a plugin for doing RSS feeds [here](https://github.com/webmasterish/vuepress-plugin-feed). I have no idea of the quality of the feed. RSS seems to be a bit of a mashup these days and I've had to hack the one I use with Hexo to get it to work in the places where it's missed a step.\n\n### Email subscriptions\nI don't currently do email subscriptions, but I imagine you can easily offload this to an external service like [MailChimp](https://mailchimp.com) or [TinyLetter](https://tinyletter.com/).\n\n## Vuepress vs Hexo\nAlright, I would never have looked into Vuepress if this wasn't in the back of my mind. Let's take a look at some of the strengths and weaknesses of the two.\n\n### Hexo\n**Pros:**\n* Simple to create new posts\n* Flexible theme options\n\n**Cons:** \n* Themes have inconsistent technologies\n* Most of the community seems to be Chinese (different social media stacks, language barriers)\n* Easier for non-developers (slightly?)\n\n### Vuepress\n**Pros:**\n* Very easy to get up and going with a basic CMS\n* Easy to create new posts\n* Themes have consistent Vue.js approach\n* Seems to have a thriving community\n\n**Cons:**\n* Not really aimed at blogging just yet (but it's coming)\n* Very developer centric\n\nI guess when the chips are down, there is not a whole lot between them. If you're not a developer with an interest in [Vue.js](https://vuejs.org/), you might not be that interested in Vuepress. For me, I like the accessibility provided for creating themes. There seems to be less magic happening in Vuepress than there seems to be with Hexo. If I were starting over, maybe I'd look at Vuepress more seriously, but I'm happy with my current process with Hexo.\n\n## Summary\nIs Vuepress worth considering for blogs? I think so. There seems to be a thriving community, and it provides a great balance between content and theming concerns. I prefer the Vue.js components to most other templating engines, though I would probably jump at an Angular-based static site generator if I found one. Finally, if you want to take a look at a whole lot of resources related to Vuepress, [this](https://github.com/ulivz/awesome-vuepress) is a great place to start.\n\nOther references:\n* https://willwillems.com/posts/building-a-website-with-vuepress.html\n* https://willwillems.com/posts/write-a-custom-theme-with-vuepress.html\n","tags":["blogging","vuejs"]},{"title":"Blogging for consistency","url":"/blogging-for-consistency/","content":"I've written a few blog posts now and I try to get feedback each time. The feedback has been great and helps me to improve. I'm building up a list of things to think about as I'm writing. In this blog, I want to focus on the feedback and highlight some of the small things that are really the big things.\n\n## Quality\nIt might seem like I should start with content, but I've found the experience of your reader has little to do with the content of the blog. I mean, yes, content IS important, but there are things that will lose you readers before they have even started getting into your content.\n\n### Fix the broken bits\nIf there is something that doesn't work, and you know it doesn't work, fix it. This might seem obvious, but I have overlooked it a couple of times now. It's just embarrassing to ask for feedback and be given a list of things that you already know aren't up to scratch.\n\n### Meet expectations\nThere is a baseline for features that you need to consider on your blog.\n* Comments (give your readers a place to interact with you and your content)\n* RSS\n* Email subscription\n* Links to easily share posts on social media\n* SEO - Your readers deserve to [find you](https://www.hanselman.com/blog/EmbraceAuthorshipTheImportanceOfRelmeAndRelauthorOnYourContentsSEOAndGoogle.aspx).\n\n### Consistency: Make a checklist\nOf course, you should have your own checklist. Here's some of the things I have been getting feedback on:\n* Filenames should be `highlighted`\n* Specify your code block types (hint: html is `markup` and command line is `bash`)\n* When writing command line code blocks, begin each command with `$` and split across lines for long statements. Identify the line break with `\\`. If adding a comment, use `#`.\n* Make sure your posts have an introduction and summary.\n* Think about your titles. You will have them for a long time. I don't like clickbait, but you should still try to get people to click. ([So.. Cloudflare...](/so-cloudflare) is a good example of a bad title)\n\n## Content\nFinally! It's time to talk about content and yes, content is important. But it's also not. Of all of the advice I've been given on content, the common theme seems to be to write about something you are actually interested in. If you're interested in what you're writing about, it will show in your writing. People will FEEL it when they read your blog. This ties back into the experience of your readers. Even if I don't understand or am uninterested in a particular topic, I may still read if the writing style takes me on a ride; if I can be put in the shoes of the writer. Convince your readers that you are invested and they will invest as well.\n\nDo you already have a checklist that you go through before posting? What else do you find important in a blog?","tags":["blogging"]},{"title":"Kubernetes: AKS and Windows Containers","url":"/kubernetes-aks-and-windows-containers/","content":"When I first heard about Windows containers, I got really excited by the idea of packaging ASP.Net legacy apps and ASP.Net Core apps consistently, without the need to remote into a VM and apply extra libraries. I soon found that Windows containers were quickly followed by a \"yeah, but\". Windows node support has recently been added to Kubernetes and AKS. I don't think it's quite ready for production, but it sure does look promising.\n\n## Why use Windows Containers?\nFirstly, we need to realise that Windows ain't Windows. There are 2 types of windows containers: \n* Windows Server Core\n* Nano Server\n\n### Windows Server Core\nWindows Server Core is mostly your standard Windows Server. If you're running .Net Framework services, you're looking here. Unfortunately, the containers are HUGE! (~~12 gig~~ 5 gig for a container)  That said, it's come a long way in the last few years. Overall, I like Windows Server Core because it allows legacy .Net Framework applications to be packaged and deployed in modern ways and these are the applications that usually really need it.\n\n### Nano Server\nNano Server solves the bloat problem with the Windows containers, coming in at a more respectable 300-ish megs, which is really exciting! \"Yeah, but\" it doesn't support .Net framework. SO it's pretty much for .Net Core projects. The problem with this is .Net Core projects really SHOULD target Linux instead. There are use cases for Nano Server, such as combining .Net Framework and .Net Core projects together on a single windows server. So, if you absolutely MUST run on Windows, Nano server has your back, though I would consider this a last resort option.\n\n## The problem with Windows containers\nI've already said that I don't think Windows containers are quite ready for production. This is mostly due to [Windows container compatibility](https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/version-compatibility). Without Hyper-V, which is not yet supported in Kubernetes, a windows container will only run on a matching host OS version. This means your host OS and container OS needs to be matched (which isn't too bad, I guess), but it also means they should be upgraded at the same time. ie. Upgrade the Windows OS on your nodes and watch your current services fail to start.\n\n## Use them anyway\nTo be honest, I'm inclined to start using Windows containers anyway. Windows Server 2019 is out. Hyper-V is coming to Kubernetes. I'm expecting Microsoft to have a migration path available soon. Realistically, it will be a while before the Host OS is upgrading and I'm expecting these issues to be solved by then. Either way, I think it's close enough that I'm prepared to look a lot closer, perhaps even as far as a staging environment.\n\n### Create a Cluster in AKS\n*NOTE:* Do the following to enable the preview features required for multiple nodepools.\n```bash\n$ az extension add --name aks-preview\n$ az feature register \\\n    --name MultiAgentpoolPreview \\\n    --namespace Microsoft.ContainerService\n\n$ az feature register \\\n    --name VMSSPreview \\\n    --namespace Microsoft.ContainerService\n```\n\nIt takes some time to register the features. Check the progress with:\n```bash\n$ az feature list \\\n    -o table \\\n    --query \"[?contains(name, 'Microsoft.ContainerService/VMSSPreview')].{Name:name,State:properties.state}\"\n```\n\nCreate the cluster: \nIn order to use multiple nodepools, we need to enable VM Scale Sets (VMSS), so make sure you do that whether you create from command line or through portal.\n\nNOTE: Password must be min 12 chars, and have Uppercase, Lowercase, numeric and Special chars\n```bash\n$ az aks create \\\n    --resource-group myResourceGroup \\\n    --name myAKSCluster \\\n    --node-count 1 \\\n    --node-vm-size Standard_B2s \\\n    --enable-addons monitoring \\\n    --kubernetes-version 1.14.0 \\\n    --generate-ssh-keys \\\n    --windows-admin-password $PASSWORD_WIN \\\n    --windows-admin-username azureuser \\\n    --enable-vmss \\\n    --network-plugin azure\n```\n\n### Create Windows nodepool\nNext add the Windows node pool with the following:\n```bash\n$ az aks nodepool add \\\n    --resource-group myResourceGroup \\\n    --cluster-name myAKSCluster \\\n    --os-type Windows \\\n    --name npwin \\\n    --node-count 1 \\\n    --node-vm-size Standard_B2s \\\n    --kubernetes-version 1.14.0\n```\n\n### Windows Pods\nI'm assuming you have connected your cluster to your kubectl, so now let's create a Pod. Of course, normally you would create a pod with a Deployment object, but we're just testing things out.\n\n```yaml\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: basiccorewin-pod\n  labels:\n    app: basiccorewin\nspec:\n  containers:\n  - name: basiccorewin\n    image: isonaj/basiccorewin:1803\n    ports:\n    - containerPort: 80\n  nodeSelector:\n    beta.kubernetes.io/os: windows\n```\n\n### My Windows Pod won't start\nThe Windows pod has been created and applied, but it won't start correctly. Instead, `kubectl get pods` is showing the pod in a RunContainerError state. Have a closer look by running `kubectl describe pod <podName>`. You're looking for 'Failed to start container' and the error message following. If it is 'The container operating system does not match the host operating system' then you have a Host OS/Container OS version mismatch.\n\n> The container operating system does not match the host operating system.\n\nSo, I ran `kubectl describe node <nodepool>` and saw that my host OS is 10.0.17763.379 (which is 1809). For the container, run `docker inspect isonaj/basiccorewin:1803` and look for OsVersion. This shows my container OS version to be 10.0.17134.766 (which is version 1803). To resolve this situation, I built a new container with an OS that matches the host I want to run on. (1809)\n\n### Node Taints\nBefore I finish up, I should really point out Node Taints. Any way you slice it, Kubernetes really expects to be running Linux under the hood and it's not possible to update ALL of the deployment yamls to specify the os-type. So how do we wrangle this split os-type monster?\n\nTaints are built for this purpose. The idea is that we tell Kubernetes not to run pods on the windows nodepool, unless we explicitly permit it.\n\n```bash\n$ kubectl get nodes\nNAME                                STATUS   ROLES   AGE     VERSION\naks-nodepool1-16426533-vmss000000   Ready    agent   3h16m   v1.14.0\nakswin000000                        Ready    agent   3h5m    v1.14.0\n\n$ kubectl taint node akswin000000 sku=win:NoSchedule\nnode/akswin000000 tainted\n```\n\nAnd done. Now if you want to run a Pod on the windows node, you need to apply a Toleration to the node, like so:\n\n```yaml\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: basiccorewin-pod\n  labels:\n    app: basiccorewin\nspec:\n  containers:\n  - name: basiccorewin\n    image: isonaj/basiccorewin\n    ports:\n    - containerPort: 80\n  nodeSelector:\n    beta.kubernetes.io/os: windows\n  tolerations:\n  - key: \"sku\"\n    operator: \"Equal\"\n    value: \"win\"\n    effect: \"NoSchedule\"\n```\n\n## Summary\nI don't think Windows containers are quite production ready, but I think they're getting pretty close to what I need. If you can match the container versions to the version of the host they will be deployed to, they seem to run quite happily. I think it's worth getting used to putting .Net Framework applications into containers and even hosting in staging. I don't think it will be long before they're ready for production.","tags":["kubernetes"]},{"title":"Kubernetes: A Beginner's Guide","url":"/kubernetes-a-beginners-guide/","content":"Kubernetes is a container orchestration platform and has been described as \"the OS of the cloud\". It builds on container-based services by providing many features such as volumes for stateful services, resilience and scaling, monitoring, automated zero-downtime upgrades. It runs on a cluster of nodes (VMs) and allocates services to nodes based on either hard limits (eg. my service must run on linux) and prioritised preferences (eg. put these two services on the same VM). If you are running your services in containers, Kubernetes will likely make your life easier.\n\n## Containers\nThe first important step is to ensure your software is running in a container. A container is a way of packaging your service, along with any dependencies, removing the reliance of specific libraries, etc existing on the OS. I'm mostly assuming you know what a container is, what the benefits are and how to run one in this blog post.\n\n## First steps\nAssuming you have a container already (and if you haven't you can just use one of mine to follow along), the first step is to create your cluster. Sorry, that part is up to you. Come back here when you're done. You can take a look at [this page](/kubernetes-setting-up-a-cluster-on-aks) for assistance with Azure.\n\n### Pods\nPods are the basic building blocks of a Kubernetes system and it's probably fair to say everything else supports Pods in keeping their services running and available. A Pod runs one or more containers and defines ports, volumes, config settings, etc to expose a container service.\n\nTo create a pod, you will need a yaml file that defines its structure. If you're not sure what yaml is, it's like a json file with way fewer characters. It uses file layout to express relationships between properties, so take care of those spaces! Anyway, here's our first yaml file:\n\n```yaml\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: basiccore-pod\n  labels:\n    app: basiccore\nspec:\n  containers:\n  - name: basiccore\n    image: isonaj/basiccore\n    ports:\n    - containerPort: 80\n  nodeSelector:\n    beta.kubernetes.io/os: linux\n```\nAlright, that is not terribly clear because it's got 'basiccore' all over it. This yaml file has 4 parts to it: apiVersion, kind, metadata and spec. We are asking for a `Pod` kind of component, from `v1` of the API. The metadata says that the name of the pod should be `basiccore-pod` and it should have one label called `app` with the value `basiccore`. Inside this pod, I want a single container running image `isonaj/basiccore` (with port `80` exposed) and the container should be called `basiccore`. The nodeSelector part is just to ensure that the linux container runs on a Linux node. (with AKS supporting windows nodepools, it helps to be sure)\n\nNow, run that on the cluster using `kubectl apply -f pod.yaml`. You can check what is happening by running `kubectl get pods`. If it shows an error, use `kubectl describe pod basiccore-pod` to find out more.\n\nOnce you're finished, there's nothing more to see. We won't actually be using this to go further. Nobody expects the spanish inquision and nobody starts a pod on its own. Delete your pod with `kubectl delete pod basiccore-pod`.\n\n### Deployments\nSo let's start over. Nobody starts a pod by itself, because there's a much better construct for running pods and that is a Deployment. A deployment will provide zero downtime by managing all sorts of things for you. It can be used to automatically rollout new image versions or pod configs (basically anything that could put your uptime at risk). We'll take a closer look in a later post.\n\nLet's jump into the yaml:\n```yaml\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: basiccore-deployment\nspec:\n  replicas: 2\n  template:\n    metadata:\n      name: basiccore-pod\n      labels:\n        app: basiccore\n    spec:\n      containers:\n      - name: basiccore\n        image: isonaj/basiccore\n        ports:\n        - containerPort: 80\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n```\n\nIt's a bit bigger than the Pod yaml. Let's work through from the top. Deployments weren't available in v1. It was added in `extensions/v1beta1`. Next, we're creating a `Deployment`, not a `Pod` and giving it a name of `basiccore-deployment`. The `spec` for a deployment consists of the number of replicas and the template. We are starting 2 Pods with this one and the template is the yaml we used to create the Pod earlier.\n\nLet's take a look:\n```bash\n$ kubectl get deployments\nNAME                   READY   UP-TO-DATE   AVAILABLE   AGE\nbasiccore-deployment   2/2     2            2           33s\n\n$ kubectl get pods\nNAME                                   READY   STATUS             RESTARTS   AGE\nbasiccore-deployment-c46759d6d-5qw96   1/1     Running            0          7s\nbasiccore-deployment-c46759d6d-f94lk   1/1     Running            0          7s\n```\n\n### Services\nWe've just spent all of this time starting and stopping pods, but we haven't actually connected to it yet. We need a way to get in, and get directed to the pod. For this, we use a Service component. \n\n> A Kubernetes Service is an abstraction layer which defines a logical set of Pods and enables external traffic exposure, load balancing and service discovery for those Pods. - kubernetes.io\n\nWhat's that mean? A service component is basically a load balancer that sits across some pods and directs the incoming requests where they are supposed to go.\n\n```yaml\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: basiccore-service\nspec:\n  type: LoadBalancer\n  selector:\n    app: basiccore\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 80\n```\nThis service will open up a port in our cluster and load balance any traffic across the pods in the selector. In this case, we're creating a service with a `type` of `LoadBalancer` targetting any pod with the metadata `app` of `basiccore` (which we applied in the deployment template).\n\nRun `kubectl apply -f basiccore-service.yaml` to apply the service and then `kubectl get services` to see the current state.\n\n```bash\n$ kubectl get services\nNAME                TYPE           CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE\nbasiccore-service   LoadBalancer   10.0.55.65   <pending>     80:30376/TCP   5m52s\n\n$ kubectl get services\nNAME                TYPE           CLUSTER-IP   EXTERNAL-IP    PORT(S)        AGE\nbasiccore-service   LoadBalancer   10.0.55.65   13.75.220.78   80:30376/TCP   8m12s\n```\n\nOnce the External IP is displayed, put that into your browser, and there it is. A container, in a pod, accessible from the outside world. \n","tags":["kubernetes"]},{"title":"Kubernetes: Setting up a cluster on AKS","url":"/kubernetes-setting-up-a-cluster-on-aks/","content":"Most cloud providers provide a managed Kubernetes cluster at this point. Each time I come back to look at Kubernetes, I feel like I've forgotten something (or everything). This post is a cheat sheet for getting a cluster up and running on Azure (using AKS) with recommended extras.  \n\n## Creating a Cluster\n### Getting ready\nFirstly, let's install the latest Azure CLI. Check [here](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest) for the latest version. Run `az --version` to see what version you have if you have it installed already. Next, `az login` and `az account set -s <subscriptionId>` so that you're ready to go.\n\nCreate the resource group: (location is important. some areas have no AKS support yet eg. australiasoutheast)\n```bash\n$ az group create --name myResourceGroup --location australiaeast\n```\n\n### Create a Linux-only cluster\nCreate the AKS cluster:\n```bash\n$az aks create \\\n    --resource-group myResourceGroup \\\n    --name myAKSCluster \\\n    --node-count 1 \\\n    --enable-addons monitoring \\\n    --generate-ssh-keys\n```\n\n### Connect kubectl to your cluster\nInstall latest kubectl using `az aks install-cli`. (You may need to update your path to find the correct kubectl.exe)\n\n```bash\n$ az aks get-credentials --resource-group myResourceGroup --name myAKSCluster\n```\n\nConnect to the Kubernetes Dashboard:\n```bash\n$ az aks browse --resource-group myResourceGroup --name myAKSCluster\n```\nIf you get permissions errors (due to RBAC), you can give cluster-admin permissions with:\n```bash\n$ kubectl create clusterrolebinding kubernetes-dashboard \\\n    -n kube-system --clusterrole=cluster-admin \\\n    --serviceaccount=kube-system:kubernetes-dashboard\n```\n","tags":["kubernetes"]},{"title":"Serverless what? Why do we need it?","url":"/serverless-what-why-do-we-need-it/","content":"\"Serverless\" was one of those terms that left me scratching my head when I first heard it. How on earth do you run a server... without a server??? That's some crazy marketing spin! What I quickly learned is that serverless is referring to how much infrastructure you need to manage. That is, none. Nada.\n\nSo who cares? I mean, I'm running on PaaS. I can change the number of servers with a slider, or set rules to automatically add and remove servers as my traffic changes. Isn't that good enough? Not according to [Troy Hunt](https://www.troyhunt.com/serverless-to-the-max-doing-big-things-for-small-dollars-with-cloudflare-workers-and-azure-functions/). When your traffic spikes (like, when your site is on the news and a million people pick up their phone at the same time and hit your site), you can go from \"too much cloud\" to \"not enough cloud\" very quickly. It's in this environment of rapidly changing traffic (and realistically, that's when it counts), that serverless really shines.\n\n## So what is it?\nAlright, so what IS serverless? Let's consider what you might be using now. You've got a few VMs on a scale set, or you've got a few VMs as nodes of a Kubernetes cluster, or maybe you have some PaaS offering where you pick the number of machines backing it. You've got some rules in place to scale up as traffic increases and then back down to reduce costs when it falls again. Each of these scenarios have:\n* a fixed monthly costs per backing VM\n* a maximum traffic threshold\n* increasing latency as the traffic approaches the threshold\n* rules to increase and decrease the number of backing VMs to trade off running cost vs latency\n\nLet's say you increase your VMs by 10x or 100x. Assuming your architecture can scale, your latency issues have just vanished. Your servers are idling with unlimited resources compared to the current load. HOWEVER, your running costs have also increased by 10x or 100x. But the servers are just idling. So, what if you only paid for the activity you caused? That fraction of a ms of CPU. That couple of KB of RAM as you process an incoming request. Assuming the price is right, wouldn't that be better? Assuming the costs are around VM rate * Utilisation, you're instantly ahead! No more scaling of resources. Costs are directly related to resources used. Oh, and one final thing. The available resources is now a DATACENTER worth of resources. Your armageddon-style traffic spike is barely a blip on their radar.\n\nThat is Serverless.\n\n## How do I use it?\nUnfortunately, serverless doesn't necessarily come for free. Architecturally, you don't run your server any more. And I mean software server, not the VM. Instead, you need to present a function based API (eg. Azure Functions or AWS Lambda) and that is effectively injected into the provider's service to execute  as configured. If you have followed a [Clean Code Architecture](https://youtu.be/_lwCVE_XgqI?list=PL7soaAB-BQAbAFa1XZkg7wOvDHorQ7KiO), it's probably simple to extract your application logic into a Functions application. If you've got application code in your controllers, or using Filters, etc, well, that will take more.\n\nSome services are Serverless already and some are not. If you want to build serverless, you're looking at:\n* Storage\n* Azure Functions\n* Service Bus\n* SignalR service\n* AKS (with virtual kubelet)\n\nIf you want to bring your serverless architecture to its knees, try:\n* SQL Server (for now - [serverless is coming](https://docs.microsoft.com/en-us/azure/sql-database/sql-database-serverless))\n* Web apps\n\nI've had a hard time putting AKS in either bucket at the moment. It runs on specific nodes (so not serverless), but there's also a virtual Kubelet that lets you use ACI as a serverless overflow. Personally, I prefer the Azure Function pricing model over the ACI pricing model and the cost of spinning up a function is MUCH lower than spinning up a container, however it might keep up if your site had a massive traffic spike. Probably somewhere between \"pure\" serverless and PaaS, but this is just a guess. So, it may be possible to use containers, AKS and Virtual Kubelet to take you some of the way towards stability within rapid traffic spikes, depending on your service startup time.\n\n## Final words\nServerless brings an extraordinary level of burst tolerance to your application, which will bring resilience and performance under extreme loads. As with any architectural decision, it's not all or nothing. You can have parts of a system that are serverless, with other parts not, such as a Web App that sends messages to a Service Bus. With a serverless backing, the web app will likely provide greater resilience under load. Use load testing to measure where your bottlenecks are. Importantly, look for any part of your architecture where serverless is hitting resource bound components. Make sure you have a fallback strategy for when the resource bound component is at maximum load.\n\nServerless is actually not a new idea and there are many serverless services available. Please refer to the [Azure Serverless services](https://azure.microsoft.com/en-us/solutions/serverless/) for more info. Effective use of serverless components in your architecture will massively increase the scalability of your application.\n","tags":["serverless"]},{"title":"So... Cloudflare...","url":"/so-cloudflare/","content":"I went to a great talk by Troy Hunt in Brisbane a while ago. Well, it was great at the time. It didn't take long before I started to realise that most of the struggles I've had with HTTPS on my blog could have actually been side stepped quite nicely by using [Cloudflare](https://www.cloudflare.com/).\n\nLet me be clear. This wasn't the first time I heard of Cloudflare. To be honest, I didn't actually know what it was before now though, and Troy has a way of presenting things so that they seem really quite simple. Cloudflare seems to provide a service that just puts a bow on hosted services: Free SSL, CDN/caching, DNS, traffic management. Cloudflare aim to have an edge within 10ms of every client on the planet.\n\nSince I already had my HTTPS sorted, I didn't worry too much about it at the time. Now, I'm looking for CDN and it wouldn't hurt to have an overlay on my site that allows some modifications to requests and responses (like HTTP/2, which Cloudflare seem to enable by default).\n\nGetting set up is easy enough.\n1. Create an account with [Cloudflare](https://www.cloudflare.com/).\n2. Add a site (eg. anthonyison.com).\n3. Set up the DNS servers with your domain provider.\n4. Add an A record to cloudflare to point to your IP (eg. for AKS) or CNAME to redirect to your alternate domain (eg. GitHub pages or web app)\n5. Wait for the change to take effect. This can take up to 48 hours.\n\nOnce CDN is in place, we've got one small problem. When we change the content, we need to be able to purge the cache. Cloudflare provides an API for achieving this. We just need to add it to the build pipeline. One way of doing it would be to create a Logic App that punches the API whenever there's a new commit on the github pages repo.\n\nI might do that later on...\n\nFor now, I've hosted both blogs, just for comparison. I'm running [Lighthouse](https://developers.google.com/web/tools/lighthouse/) against both to see if there's much of a difference.\n\nRunning Ghost:\n![Ghost Summary](/so-cloudflare/ghost_summary.png)\n![Ghost Performance](/so-cloudflare/ghost_performance.png)\n\nRunning Hexo on Github Pages:\n![Ghost Summary](/so-cloudflare/github_summary.png)\n![Ghost Performance](/so-cloudflare/github_performance.png)\n\nRunning Hexo on Github Pages behind Cloudflare:\n![Ghost Summary](/so-cloudflare/cloudflare_summary.png)\n![Ghost Performance](/so-cloudflare/cloudflare_performance.png)\n\n\nWith Cloudflare in place, I have CDN, HTTPS, HTTP/2 in place. I've enable Rocket Loader to improve paint time and auto-minify so that I can pull that from my build process. I can enable HSTS automatically, but not sure it's necessary?\n\nFor now, I think the numbers are heading in the right direction, even though I seem to have introduced a couple of new issues while migrating to hexo.","tags":["CDN"]},{"title":"Migrating from Ghost to Hexo","url":"/migrating-from-ghost-to-hexo/","content":"It was surprisingly easy to migrate my blog out of ghost, but there were a few missed steps along the way. Often, I would find a better way after I had done the heavy lifting.\n\n## 1. Install Hexo and create the blog\n```bash\n$ npm install hexo-cli -g\n$ hexo init myblog\n$ cd myblog\n```\n\n## 2. Install the hexo-casper theme\n```bash\n$ git clone https://github.com/xzhih/hexo-theme-casper.git themes/hexo-casper\n```\n\n## 3. Configure the theme and site\nEdit `_config.yaml`\n```yaml\n# Site\ntitle: Anthony Ison\nsubtitle: Software development and DevOps. Bringing solutions to life.\ndescription: My meandering thoughts on development, devops and technology\nkeywords: software development,devops,azure,kubernetes,angular,serverless,docker\nauthor: Anthony Ison\nlanguage: en\ntimezone: Australia/Brisbane  # From http://momentjs.com/timezone/\nurl: http://anthonyison.com\nroot: /\n\n# Set these to create lowercase, title-only permalinks (like ghost)\npermalink: :title/\nfilename_case: 1\n\n# consider creating a folder with each post to hold any assets\npost_asset_folder: true\n```\n\nEdit `themes/hexo-casper/_config.yaml`\n\n## 4. Migrate posts from ghost to hexo\nIn Ghost:\nLabs > Export content\n\n```bash\n$ npm install hexo-migrator-ghost --save\n$ hexo migrate ghost my-ghost.json\n```\n*FAILED!*\n\n```bash\n$ npm install hexo-migrator-tryghost --save\n$ hexo migrate ghost my-ghost.json\n```\n*FAILED!*\n\nThese probably failed because I was running Ghost 2.x and the export format has changed. If you've got an earlier version, maybe this will work for you.\n\n```bash\n$ docker run -it -v $(pwd):/temp golang\n$ go get -v github.com/jqs7/ghost-hexo-migrator\n$ cd /temp\n$ ghost-hexo-migrator my-ghost.json\n```\n*FAILED!*\n\nThis got a little closer, and actually pulled content across, but now I'm out of options. Fortunately, I don't have many posts and will manually migrate instead. I hope you have better luck.\n\n## 5. Reattach the post images\nMany of the migration tools will bring content across without images. So afterwards, you will need to copy the images in and link them to posts manually.\n\nAlso, it's worth configuring an image optimizer, using:\n```bash\n$ npm i hexo-filter-responsive-images --save\n```\n\nThen add to the `_config.yaml`:\n```yaml\n# hexo-filter-responsive-images\nresponsive_images:\n  pattern: '**/*.+(png|jpg|jpeg)'\n  sizes:\n    small:\n      width: 800\n      withoutEnlargement: true\n    large:\n      width: 2000\n      withoutEnlargement: true\n```\n\nTo each of the blog post headers, add:\n```yaml\nimage: my-blog-post/small_cover.jpg\nfeature_img: large_cover.jpg\n```\nwhere `cover.jpg` is the original image for the post cover.\n\n## 6. Configure RSS\n```bash\n$ npm install hexo-generator-feed --save\n```\n\nAdd this to your `_config.yaml`:\n```yaml\nfeed:\n  type: atom\n  path: atom.xml\n  limit: 20\n  hub:\n  content:\n  content_limit: 140\n  content_limit_delim: ' '\n  order_by: -date\n  icon: icon.png\n```\n\n## 7. Configure deploy\n```bash\n$ npm install hexo-deployer-git --save\n```\n\nEdit `_config.yaml`\n```yaml\ndeploy:\n  type: git\n  repo: https://github.com/isonaj/isonaj.github.io.git\n  branch: master\n```\n\n","tags":["blogging","ghost","hexo"]},{"title":"Serverless markdown blogs with Hexo","url":"/serverless-markdown-blogs-with-hexo/","content":"Let me start this by saying I'm loving my ghost blog, and I get a kick out of running it on AKS. The thing is, the content only changes when I post and so I'm thinking about caching and I realise the whole blog can be cached. It's not an API. I don't have changing data. (Ok, TECHNICALLY I have a db, but bear with me) My posts are markdown, and I could just store them in git and publish static pages when I push.\n\nAfter some searching, I have found there are many static web site generators. The ones that stood out for me were: \n* [Jekyll](https://jekyllrb.com/) - this is number 1 and the default in [Github Pages](https://pages.github.com/). It runs on Ruby.\n* [Hexo](https://hexo.io/) - this is huge in China and built on node\n* [Vuepress](https://vuepress.vuejs.org/) - built for Vue docs. I think I will love this when the project is a bit more mature.\n\n> I thought I'd review Jekyll and Hexo, so I pulled a jekyll container in one window and installed Hexo in another. Unfortunately, I was up and running with Hexo before my download even finished, so rather than having a post that contrasts the two, I seem to have already chosen Hexo.\n\n## Jekyll\nThis is far and away the most popular. It has a thiving community and is well supported by Github Pages. The main disadvantage is that it becomes exponentially slower as pages are added, which wouldn't likely be an issue for my blog but is worth noting.\n\n## Hexo\nHexo is number 2 in popularity (mostly in China) and is growing fast. It also has many themes, and most of the demo sites are in Chinese.\n\n### Installing Hexo\nSince it's built on node, Hexo is super easy to install (assuming you already have node installed!) We will be using npm to install.\n\n```bash\n# Install Hexo:\n$ npm install hexo-cli -g\n\n# Create a site:\n$ hexo init my-site\n\n# Create a post:\n$ hexo new post \"This is going to be a great post\"\n\n# Serve your site locally:\n$ hexo serve\n\n# Generate the static site:\n$ hexo generate\n```\n\nYou can also:\n* Create a draft with `hexo new draft \"This is a draft post\"`\n* Publish a draft with `hexo publish post this-is-a-draft-post`\n* Deploy your site: `hexo deploy`\n\n### Themes\nThere are many themes around. Usually, you pull a git repo into your themes/theme-name folder. Themes basically wrap the whole presentation process, which means each theme has specific capabilities. (eg. some have google analytics, some have disqus comments). If you want to mix and match, you quickly find yourself editing your theme.\n\n### Plugins\nThere are different types of plugins. They seem to hook into the build process and provide various services. I haven't looked into them too much yet.\n\n### Migrators\nThere are migrators available and you can pull them in with npm install. I quickly found migrators for Wordpress and Ghost blogs. \n\n## Summary\nHexo is node-based and provides a familiar interface for an Angular developer. It is a fantasic tool for getting a blog up and running and has capability to migrate from existing platforms. Since it is git based, it's a bit harder to manage from my phone, however I LOVE that my markdown content is in git so I can review changes and I know it won't be lost in a corrupt database.\n\nWhat do you think? Would you use Hexo?","tags":["hexo"]},{"title":"Dynamic environment in your static Angular application","url":"/dynamic-environment-in-your-static-angular-application/","content":"I keep hitting the same problem when building Angular applications. Environment settings! They are easy to set up in development, but as you target different environments, the old \"one file per environment\" really doesn't cut it. I don't want to rebuild my application just to deploy to production and if it's in a container? Pfft, good luck! I've solved this problem a few different ways in the past and I've just solved it again. But this time, it didn't feel quite so hacky, so I thought I'd post about it.\n\n## Problem\nAngular CLI provides an `environment.ts` for storing your global settings and you can select which environment file to use when you build. I want to build my application once and then deploy to different environments without rebuilding, however I can't change my environment settings on deploy or through environment variables. There are a few reasons I don't want to rebuild.\n\n1. I want to test in staging and then redeploy the artifact to production\n2. I want to run it from a container\n\n## Solution\nOk, so this is not a new problem and it has been reasonably solved on server side deployments a few ways:\n\n1. Environment variables / web.config / appsettings.json - config is easily overridden in place and is often used for server config settings.\n2. Rewrite on deploy - the deployment script itself can overwrite settings as it is deployed to configure the environment it is deploying to.\n\n### Option 1: Inject bootstrap settings into the index.html\nThis was my first attempt at solving the problem. I added a comment in the index.html and created an MVC endpoint to load the index.html file, replace the comment with a script block to create a settings object and return the updated html page. It was good for keeping the number of requests down, but it felt a bit hacky.\n\n### Option 2: A separate bootstrap script file\nThis approach was inspired by [this post](https://www.jvandemo.com/how-to-configure-your-angularjs-application-using-environment-variables/). The basic idea is to pull a separate self-executing script that contains our bootstrap settings from the `index.html`.\n\n```markup\n<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <title>My Awesome Angular app</title>\n    <base href=\"/\">\n    <meta name=\"viewport\" \n          content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n    <!-- Load environment variables -->\n    <script src=\"assets/bootstrap.js\"></script>  \n  </head>\n  <body>\n    <app-root></app-root>\n  </body>\n</html>\n```\n\nNext, create the `bootstrap.js` file in your assets folder. It should look something like this:\n```javascript\n(function (window) {\n  window.bootstrapSettings = {\n    apiUrl: 'https://localhost:44384',\n    production: false,\n  };\n}(this));\n```\n\nWhen the angular app loads, we now have a bootstrap object available to pull settings from. In this case, I can reference `window.bootstrapSettings.apiUrl` to find my api location, but I'm trying to use `environment.apiUrl`.\n\nNext, we need to update `environment.ts` to bring in the bootstrap settings.\n\n```typescript\nexport const environment = Object.assign({\n    production: false,\n  },\n  (window as any).bootstrapSettings);\n```\n\nAt this point, we can build once and serve from different static sites by simply applying a different `assets/bootstrap.js` file with the new settings during deployment.\n\nThis is good, but we're serving from dotnet core, so we can do better. (If you're using node, the idea is not much different). The basic idea is to avoid serving the static bootstrap file and instead, send a bootstrap file based on our appsettings file, which we can easily override from our environment (web app, container, etc) using the middleware below.\n\n```csharp\npublic class EnvironmentBootstrap\n{\n    public string apiUrl { get; set; }\n}\n\npublic static class EnvironmentBootstrapExtensions\n{\n    public static IApplicationBuilder UseEnvironmentBootstrap(\n\t\tthis IApplicationBuilder builder, string path)\n    {\n        return builder.UseMiddleware<EnvironmentBootstrapMiddleware>(path);\n    }\n}\n\npublic class EnvironmentBootstrapMiddleware\n{\n    private readonly RequestDelegate _next;\n    private readonly EnvironmentBootstrap _environment;\n    private readonly string _endpointPath;\n\n    public EnvironmentBootstrapMiddleware(\n    \tRequestDelegate next, \n        IOptions<EnvironmentBootstrap> options, \n        string path)\n    {\n        _next = next;\n        _endpointPath = path;\n        _environment = options.Value;\n    }\n\n    public async Task Invoke(HttpContext httpContext)\n    {\n        // Short circuit on request for bootstrap.js\n        if (httpContext.Request.Path\n            .Equals(_endpointPath, StringComparison.Ordinal))\n        {\n            httpContext.Response.ContentType = \"application/javascript\";\n            await httpContext.Response.WriteAsync(\n            \t\"(function (window) { window.bootstrapSettings = \" +\n            \tJsonConvert.SerializeObject(_environment) + \n            \t\";}(this));\");\n        }\n        else\n            // Pass to next item in the pipeline\n            await _next.Invoke(httpContext);\n    }\n}\n```\n\nFinally, activate the pipeline in the Startup.cs file:\n```csharp\npublic class Startup\n{\n    public void ConfigureServices(IServiceCollection services)\n    {\n        // ...\n        services.Configure<EnvironmentBootstrap>(\n            Configuration.GetSection(\"client\"));\n        // ...\n    }\n                    \n    public void Configure(IApplicationBuilder app)\n    {\n        // ...\n        // Bootstrap the bootstrap.js file ahead of UseStaticFiles\n        app.UseEnvironmentBootstrap(\"/assets/bootstrap.js\");\n        app.UseStaticFiles();\n        app.UseSpaStaticFiles();\n        // ...\n    }\n}\n```\n\nThat's it! The project can now be built once and deployed to different environments, with angular client environment settings available to be configured from the environment itself. For an Azure Web app, set an Application Setting 'client:apiUrl' to override the client's `apiUrl` environment setting.\n\nWhat do you think? Is there a better solution? What do you like or dislike about this approach?","tags":["dotnet","angular"]},{"title":"Automatic HTTPS on Kubernetes","url":"/automatic-https-on-kubernetes/","content":"This post starts with a slight regret that I didn't get Ghost running on a Web App.  One of the brilliant parts of a Web App is that you can force all requests over HTTPS with the click of a button. Of course, I'd still need to organise a certificate for my domain. Hold on, let me stop and back up a minute.\n\nWhat the heck is this HTTPS and certificate stuff? Basically, HTTPS will guarantee that the communication between the client and server can't be read or changed by anyone between the client and server. So, usernames and passwords are safe to send. While that's important, it's probably more important that your pages cannot be changed either. It's a bit like a message written in code with the king's seal. Since the code (HTTPS) is known to you and the king, you know it cannot be read. The seal (certificate) proves the authenticity.\n\nAs I set out on this adventure, it looks like I need cert-manager and the best way to install this appears to be to use helm, which I installed with Chocolatey.\n\n```bash\n$ choco install kubernetes-helm\n$ helm init\n```\n\n## First steps\nWe are going to install cert-manager which will perform all of the magic of fetching certificates and storing them for use in our various services. We need to set up the config for cert-manager, so that we can provide the link to Lets Encrypt. Save the following in a file, say issuer.yaml, and run `kubectl apply -f issuer.yaml` to apply. (Make sure you update with your email first!)\n\n```yaml\napiVersion: certmanager.k8s.io/v1alpha1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory    \n    email: youremail@gmail.com\n    privateKeySecretRef:\n      name: letsencrypt-prod\n    http01: {}\n```\n\n## Installing cert manager\n```bash\n$ kubectl apply -f \\\n    https://raw.githubusercontent.com/jetstack/cert-manager/release-0.6/deploy/manifests/00-crds.yaml\n\n$ helm install --name cert-manager --namespace ingress \\\n    --set ingressShim.defaultIssuerName=letsencrypt-prod \n    --set ingressShim.defaultIssuerKind=ClusterIssuer \n    stable/cert-manager\n```\n\nI ran into issues installing cert-manager with a 'cluster-admin' not found error. I found instructions on [this page](https://docs.bitnami.com/azure/get-started-aks/) which helped me create a cluster admin role, create a service account and assign tiller to it.\n\n## Installing nginx-ingress\nThe next step is to configure an Ingress to manage the TLS endpoint, that is to manage my HTTPS endpoint with certificate connected to my domain. Without this step, I found I could set up my Ingress entry, but the address would stay empty.\n\n```bash\n$ helm install stable/nginx-ingress \\\n    --name nginx \\\n    --set rbac.create=true \\\n    --namespace ingress\n```\n\nOnce installed, I can see a LoadBalancer entry which has my External IP on it.\n\n## Update the Service\nIn the previous post, we set the service up as a LoadBalancer type. We don't need that any more since we have a new IP on our LoadBalancer nginx-ingress service. Update the service.yaml and change LoadBalancer to a NodePort and run `kubectl apply -f service.yaml`. This will make sure we can only access our service through our TLS ingress service.\n\n## Generate Certificate and Ingress for Service\nApply the following updates to the kubernetes cluster.\n\n```yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: anthonyison-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    certmanager.k8s.io/cluster-issuer: letsencrypt-prod\nspec:\n  tls:\n  - hosts:\n    - anthonyison.com\n    secretName: anthonyison-crt\n  rules:\n  - host: anthonyison.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: anthonyison\n          servicePort: 80\n```\n\n```yaml\napiVersion: certmanager.k8s.io/v1alpha1\nkind: Certificate\nmetadata:\n  name: anthonyison-crt\nspec:\n  secretName: anthonyison-crt\n  dnsNames:\n  - anthonyison.com\n  acme:\n    config:\n    - http01:\n        ingressClass: nginx\n      domains:\n      - anthonyison.com\n  issuerRef:\n    name: letsencrypt-prod\n    kind: ClusterIssuer\n```\n\nThat's it!  Hit your domain and confirm that https is working. You should be able to click on the padlock in the address bar and click on Certificate to see the details. You should see a certificate issued by Lets Encrypt to your domain name.\n\nSo, I started off with some regret that I wasn't running in a Web App. While it took quite a while to work through many of the issues that showed up along the way, it is actually pretty easy once it's set up, and furthermore, I don't have to think about my certificates ever again. I think maybe it's not as bad as I thought. No regrets, right?\n\n### References:\n1. [Automated TLS with Cert Manager and Lets Encrypt for Kubernetes](https://itnext.io/automated-tls-with-cert-manager-and-letsencrypt-for-kubernetes-7daaa5e0cae4)\n2. [Get automatic HTTPS with Lets Encrpyt and Kubernetes Ingress](https://akomljen.com/get-automatic-https-with-lets-encrypt-and-kubernetes-ingress/)\n3. [How to use Lets Encrypt on Kubernetes (without Cert Manager)](https://runnable.com/blog/how-to-use-lets-encrypt-on-kubernetes)\n4. [Configuring AKS](https://docs.bitnami.com/azure/get-started-aks/)\n5. [Secure your Kubernetes Services using Cert Manager](https://dzone.com/articles/secure-your-kubernetes-services-using-cert-manager)","tags":["kubernetes"]},{"title":"Running Ghost on Kubernetes on Azure","url":"/running-ghost-on-kubernetes-on-azure/","content":"In my [previous post](/creating-a-blog-with-ghost/), I was looking into a few options for running my blog. I think at this time, I'm going to keep it on Azure because I can run it for free. I suspect I would make a different choice if not for my bonus credits. I will need some benchmark figures to choose a provider, however kubernetes should give me the platform I need to change in the future if necessary.\n\nI have a basic level of understanding of how kubernetes hangs together and would love to hear your feedback if you would do things differently. The basic idea is to run a ghost container and provide persistent storage for the content. In the future, I would like to use nginx to reverse proxy incoming traffic and to provide HTTPS for my site.\n\nI have used AKS to generate a kubernetes cluster and my kubectl is configured to connect to it. First, I need to configure my storage. For this, I use a yaml file.\n\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: anthonyison-content\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: default\n```\n\nUsing `kubectl apply -f volume.yaml` we can generate the volume claim to be used in the next step. Next, we will generate a deployment for the the ghost container, linking it to the anthonyison-content volume.\n\n```yaml\napiVersion: apps/v1beta1\nkind: Deployment\nmetadata:\n  name: anthonyison\n  labels:\n    app: anthonyison\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: anthonyison\n  template:\n    metadata:\n      labels:\n        app: anthonyison\n    spec:\n      containers:\n      - name: anthonyison\n        image: ghost:2.9.1-alpine\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 2368\n        env:\n        - name: url\n          value: http://anthonyison.com\n        volumeMounts:\n        - mountPath: /var/lib/ghost/content\n          name: content\n      volumes:\n      - name: content\n        persistentVolumeClaim:\n          claimName: anthonyison-content\n```\n\nSo now we have a ghost container running in Kubernetes with an external mounted volume for storing content. However, it's not exposed as yet. We do that with a Service. The `service.yaml` is below.\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: anthonyison\nspec:\n  type: LoadBalancer\n  selector:\n    app: anthonyison\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 2368\n```\n\nAnd that's actually all there is to it. By running `kubectl get services` you can see the External IP. If you put that in the browser, you will go to the new blog. Better still, put the IP into your DNS A record, and your domain name will direct to the new site.","tags":["kubernetes","ghost","azure"]},{"title":"Creating a blog with Ghost","url":"/creating-a-blog-with-ghost/","content":"There seems to come a time in a software developer's life where you look at creating a blog. It's that time for me. I want a place where I can write up some of my experiments for later reference, and if that can help others along the way, all the better!\n\n## Considerations\n1. I don't want to pay anything. I really don't want to break the bank with this project. If I can pay nothing, I will. This puts [Azure](https://azure.com) squarely in the front seat because I have $70 a month to spend there.\n2. Easy to use. I don't want to spend ages messing with this project, or debugging issues.\n3. Broad application / reusable. It would be great if this thing can be used for more than just this blog. If I can host other sites or blogs on the same infrastructure, that would be kinda handy.\n4. Preferably something I want to learn. Cause, you know. What's the point otherwise?\n\nAt first, I had thought I'd be using [Wordpress](https://wordpress.org) and I wasn't really looking forward to that. On the upside, there are wordpress containers around and I was pretty keen to run it in a container.\n\nAfter a quick email with [Thiago](https://passos.com.au), I started looking at [Ghost](https://ghost.org). Once I knew it was there, I noticed that many of the blogs I read, including [Troy Hunt](https://www.troyhunt.com), are powered by Ghost. With little more than that meagre planning, it was time to get started.\n\n## Attempt 1: Azure Web apps\nFirstly, I needed a place to host it. I'm an Azure guy, so I started there. It seemed to be straight forward enough. A ghost container, wrapped in a Web App, running on Linux, volume mapped to a Azure File storage. I ran it locally and it worked perfectly. Once installed on Azure, I found the database just wouldn't load up correctly, giving Migration errors, saying that the database was locked.\n\nFirst attempt foiled!\n\n## Attempt 2: Google GKE\nMy next attempt was to spin it up on GKE on to [Google cloud](https://cloud.google.com). [Kubernetes](https://kubernetes.io) seemed to be a bit of overkill for what I was trying, but Google made that super easy, and it pretty much \"just worked\".\n\nThat left me with the question, what about AKS on Azure?\n\n## Attempt 3: Azure AKS\nI've never created an AKS cluster. I mean, I've wanted to. Who hasn't? The thing is, I've never actually clicked the Go button. So, I guess it's time. It was easy enough to configure as well and then I clicked Create and waited. I waited and then I waited some more. I went looking for any events showing that something was happening, but couldn't see anything. So I tried again and this time, it worked.\n\nIt spun up easy enough and with minor changes to the PersistentVolumeClaim, it just worked as well, albeit it a bit slower than GKE, which was odd because I had double the resources on Azure.\n\n## So, now what?\nAlright, so now I seem to be on the kubernetes train. Even writing it now, it seems kinda crazy to spin up a kubernetes cluster to run a blog that is probably only going to have me as traffic. But it is expandable. There are a couple of sites I want to host. They're currently in containers on Azure Web apps, but should move across easy enough.\n\nI'm still not sure of cost. I will run both solutions for a couple of days and have a look at what charges come through. I hadn't planned to move from Azure at this time. That's where I have the most experience.\n\n## Next steps\n1. Run some performance and pricing measures to compare GKE vs AKS and decide where my blog will stay.\n2. Write up the technical steps for creating the blog.\n3. Enable the site to run [HTTPS](https://www.troyhunt.com/the-6-step-happy-path-to-https/) with [Let's Encrypt](https://letsencrypt.org) certificates.","tags":["ghost"]}]