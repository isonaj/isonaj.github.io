{"meta":{"title":"Anthony Ison","subtitle":"Software development and DevOps. Bringing solutions to life.","description":"Software development and DevOps. Bringing solutions to life.","author":"Anthony Ison","url":"https://anthonyison.com","root":"/"},"pages":[{"title":"","date":"2019-07-16T10:36:17.587Z","updated":"2019-07-16T10:36:17.587Z","comments":true,"path":"README.html","permalink":"https://anthonyison.com/README.html","excerpt":"","text":""},{"title":"about","date":"2019-05-03T10:36:22.000Z","updated":"2019-05-03T10:48:16.414Z","comments":true,"path":"about/index.html","permalink":"https://anthonyison.com/about/index.html","excerpt":"Anthony is a Senior Software Architect in the Brisbane office and brings 20 years of development experience across many industries including stockbroking, microfinance and point of sale. He has a keen interest in software and database performance, reducing running costs and reducing problems through","text":"Anthony is a Senior Software Architect in the Brisbane office and brings 20 years of development experience across many industries including stockbroking, microfinance and point of sale. He has a keen interest in software and database performance, reducing running costs and reducing problems through simple solutions. His experience in team lead and agile coaching roles contributes to his ability to produce great outcomes for clients. In his spare time, he loves playing with new technologies and making cold press coffee and various liqueurs. He is strongly motivated to give back to the community as a token of gratitude to all of the great mentors he’s had throughout his career."},{"title":"cwl","date":"2019-06-03T08:04:02.000Z","updated":"2019-07-02T11:59:33.099Z","comments":true,"path":"cwl/index.html","permalink":"https://anthonyison.com/cwl/index.html","excerpt":"NameWar 1War 2War 3War 4War 5War 6War 7Total pugnacious11111117 torrville00000000 archylles11111117 tonydipinto11111117 landonville00000000 lil row01111116 42311011116 hami11101116 aton11110116 pug11111016 nug11111106 archys01111116 baldrik11011116 nat the brat11101116 wizzoliver11110116 mufelicious","text":"NameWar 1War 2War 3War 4War 5War 6War 7Totalpugnacious11111117torrville00000000archylles11111117tonydipinto11111117landonville00000000lil row0111111642311011116hami11101116aton11110116pug11111016nug11111106archys01111116baldrik11011116nat the brat11101116wizzoliver11110116mufelicious10111116mufarsa10111116nacho11111016trent11111106Total:15151515151515"}],"posts":[{"title":"Refactoring code - restructure, not rewrite","slug":"refactoring-code-restructure-not-rewrite","date":"2019-07-30T05:35:28.000Z","updated":"2019-07-31T08:51:27.798Z","comments":true,"path":"refactoring-code-restructure-not-rewrite/","link":"","permalink":"https://anthonyison.com/refactoring-code-restructure-not-rewrite/","excerpt":"I see a lot of similarities between software and business processes. If I’m talking about a queuing mechanism, it often helps to describe it as a call centre managing their tickets, or a lock as being like a key for the toilets. Refactoring then, would simply be a restructuring of a business or to g","text":"I see a lot of similarities between software and business processes. If I’m talking about a queuing mechanism, it often helps to describe it as a call centre managing their tickets, or a lock as being like a key for the toilets. Refactoring then, would simply be a restructuring of a business or to give someone a new title or change teams around, however software developers often use it to mean they want fire everyone and start over. When we compare software processes and business processes, it can make it easy to communicate the benefits or drawbacks of a particular solution. Furthermore, when the stakeholders are engaged in the conversation and they understand what’s being discussed they can guide the process more easily and it becomes a win-win for the software developers and the business. But I digress… Let’s get back to the dreaded rewrite. It’s always possible that a business is in a state where this is needed, however small changes to a working system can produce incredible results. Software is expensive. I mean, REALLY expensive. So, let’s not burn down the house just because we no longer like the decor. As a software developer, refactoring is a one of your daily chores. The thing about a daily chore is that, when it’s not done, it kind of builds up. If you never do your chores, you might find that you have a BIG job to get things neat and tidy again. And then, even if you stay on top of your chores, you might find you need an spring clean now and then just to get to the areas that aren’t being kept on a daily basis. The problem is, software developers don’t seem to agree on what refactoring is. It is often used to mean fixing a bug by writing “clean code” (or code that introduces design patterns) instead of “messy code”. That’s not refactoring though, and as a community, we need to understand what refactoring is. So what is it? I’ve never seen one before. No one has, but I’m guessing it’s a white hole - Kryten Refactoring is a change made to the internal structure of existing software to make it easier to understand and cheaper to modify without changing its observable behaviour. It does not mean “cleaning up code”. Basically, if you are fixing an issue or adding new behaviour, you are NOT refactoring. It is often an iterative, mechanical process that is practically risk-free. How can it be risk-free? Well, the types of changes we are talking about are renaming methods or variables or extracting a small chunk of code from one method into another. WARNING: I’m about to show an example of refactoring some code. If you’re not a software developer, focus on the difference between the starting code and the finished product. Consider the following example: // ... var t = this.Items.Sum(i => i.Qty * i.Price); t -= Math.Round(this.Discount * t, 2); var tt = Math.Round(t / 11, 2); // ... There are a few issues with this example. Let’s fix some of the variables. var subtotal = this.Items.Sum(i => i.Qty * i.Price); var discount = Math.Round(this.Discount * subtotal, 2); var total = subtotal - discount; var gst = Math.Round(total / 11, 2); There is a code smell here with the parent accessing the child data (Qty and Price) to calculate the item subtotal. I think my first step here would be to add a get property to the child class to handle this. var subtotal = this.Items.Sum(i => i.Subtotal); var discount = Math.Round(this.Discount * subtotal, 2); var total = subtotal - discount; var gst = Math.Round(total / 11, 2); Finally, the tax calculation has a hardcoded tax rate and it’s not clear that this is actually calculating Gst, so let’s move it to a global Gst calculator. I’m also not sure how often Gst is calculated, but this provides a single location to update all Gst calculation in the case that the rate changes. var subtotal = this.Items.Sum(i => i.Subtotal); var discount = Math.Round(this.Discount * subtotal, 2); var total = subtotal - discount; var gst = GstCalculator.CalculateTax(total); As you can see, the refactored code should produce the same results as the original code and has significant improvements to readability, mostly from renaming variables. It may not be immediately obvious that the extra context from naming helps to document the code without actually adding comments. Refactoring TechniquesI mentioned earlier that refactoring is a mechanical process. In fact, there are a list of known refactoring techniques as well as Martin Fowler’s catalog. Be aware that for every refactoring, there is an equal and opposite refactoring. There is not really a “best way” to lay out your code. Instead, you need to choose a refactoring that “improves” your code. If the code is overly complex, you might be looking at refactorings that reduce complexity. Alternatively, you might increase complexity to gain flexibility. Refactoring is a disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behaviour - Martin Fowler The main benefits of refactoring are increased maintainability and extensibility with a low risk of introducing new issues. Like Test Driven Development (TDD), refactoring requires discipline to gain the full benefit from the practice. While each change seems too small to bother with, the cumulative effect of the practice will transform your code. If you want to learn more about refactoring techniques, I highly recommend the book, Refactoring: Improving the Design of Existing Code. Originally published in 1999, it’s recently had a 2nd edition. The idea of refactoring has been around for a long time and seems to be largely misunderstood by the software development community. By consistently refactoring before writing new code, software developers are able to improve the code base and improve maintainability and extensibility even to legacy applications.","categories":[],"tags":[{"name":"principles","slug":"principles","permalink":"https://anthonyison.com/tags/principles/"}]},{"title":"Static Site Generation with Vuepress","slug":"static-site-generation-with-vuepress","date":"2019-07-10T12:20:34.000Z","updated":"2019-07-25T12:40:43.594Z","comments":true,"path":"static-site-generation-with-vuepress/","link":"","permalink":"https://anthonyison.com/static-site-generation-with-vuepress/","excerpt":"When I was reviewing static site generators, Vuepress caught my eye but I passed over it quickly because their web site admitted that they lacked blogging support. I really liked the approach though. It uses the Vue.js server-side processing to generate static sites. It’s time to have a closer look.","text":"When I was reviewing static site generators, Vuepress caught my eye but I passed over it quickly because their web site admitted that they lacked blogging support. I really liked the approach though. It uses the Vue.js server-side processing to generate static sites. It’s time to have a closer look. UPDATE 2019-07-18: “Vuepress lacks blogging support” is no longer accurate. Vuepress has added A LOT of features in version 1.0 that addresses the issues I experienced while writing this post. Stay tuned for another post on Vuepress soon! Creating contentMy first measure of a tool is how easy it is to get started. For Vuepress, that means I want to create a couple of posts. It’s really easy to create some quick content, like so: # Create a folder for the blog $ mkdir myblog $ cd myblog # Create a package.json file and add vuepress $ npm init # Enter through to accept all defaults $ npm i vuepress --save Create the following files:post1.md: # My first post Here is some content post2.md: # My second post Here is some more content index.md: # Index * [First post](/post1.md) * [Second post](/post2.md) Next, we need to configure npm to run vuepress for us. Edit the newly created package.json file in the current folder and change the scripts section to: \"scripts\": { \"dev\": \"vuepress dev\", \"build\": \"vuepress build\" }, You can now run npm run dev to serve your blog. Ok, so it wasn’t THAT easy to get started. I would really prefer to see some kind of init stage here instead, but it’s not too bad and you only have to get set up once. I’m guessing these concerns would be addressed if/when they add blogging support. Looking at the new site, it’s pretty barebones but it already has a search box that can look up my posts by title, so there’s that. What we have at this point is basically a wiki page. While that’s ok, I actually just want to create blog posts. I don’t want to have to build links from my main page to each post. Let’s take a look at themes. Adding a themeVuepress provides a clear separation between the content and the theme. The theme pieces will all live in the .vuepress folder. That is, any site configuration, layouts, components, etc can be found in this folder. Let’s try out some of this now. ConfigurationCreate the .vuepress folder and add a config.js file with the following: module.exports = { title: 'My Vuepress Blog', description: 'Taking Vuepress for a spin' } Default LayoutYou can easily export the starting default theme by running npx vuepress extract. This will save the default layout in the .vuepress\\theme folder. I’m not going to open up themes too much just yet. That would be a whole blog post to itself, but if you’re interested in digging in, I recommend this post. Figure: Vuepress site with default layout Downloading a themeIf you’re like me, you’re not interested in the absolute nitty-gritty of the theme. You just want to generate content. What I like about Vuepress is that the theme is Vue.js and I can have a good crack at trying to maintain my theme, or tweak the theme as needed. As you can see in my blog, I am captivated by the Casper theme and fortunately, Vuepress has a Casper theme here. In my mind though, this theme leaves a lot to be desired when compared to my current (tweaked) hexo casper theme. This one requires the reading time to be added to the frontmatter, but that could possibly be automated with this plugin. Figure: Vuepress site with Casper layout Blogging supportIn this post, I looked at some of the expectations for a blog. Let’s take a look at which parts we can hit with Vuepress. CommentsI use Disqus for comments. It uses JS to plugin to your page so should be able to run pretty much anywhere. RSSVuepress has a plugin for doing RSS feeds here. I have no idea of the quality of the feed. RSS seems to be a bit of a mashup these days and I’ve had to hack the one I use with Hexo to get it to work in the places where it’s missed a step. Email subscriptionsI don’t currently do email subscriptions, but I imagine you can easily offload this to an external service like MailChimp or TinyLetter. Vuepress vs HexoAlright, I would never have looked into Vuepress if this wasn’t in the back of my mind. Let’s take a look at some of the strengths and weaknesses of the two. HexoPros: Simple to create new posts Flexible theme options Cons: Themes have inconsistent technologies Most of the community seems to be Chinese (different social media stacks, language barriers) Easier for non-developers (slightly?) VuepressPros: Very easy to get up and going with a basic CMS Easy to create new posts Themes have consistent Vue.js approach Seems to have a thriving community Cons: Not really aimed at blogging just yet (but it’s coming) Very developer centric I guess when the chips are down, there is not a whole lot between them. If you’re not a developer with an interest in Vue.js, you might not be that interested in Vuepress. For me, I like the accessibility provided for creating themes. There seems to be less magic happening in Vuepress than there seems to be with Hexo. If I were starting over, maybe I’d look at Vuepress more seriously, but I’m happy with my current process with Hexo. SummaryIs Vuepress worth considering for blogs? I think so. There seems to be a thriving community, and it provides a great balance between content and theming concerns. I prefer the Vue.js components to most other templating engines, though I would probably jump at an Angular-based static site generator if I found one. Finally, if you want to take a look at a whole lot of resources related to Vuepress, this is a great place to start. Other references: https://willwillems.com/posts/building-a-website-with-vuepress.html https://willwillems.com/posts/write-a-custom-theme-with-vuepress.html","categories":[],"tags":[{"name":"blogging","slug":"blogging","permalink":"https://anthonyison.com/tags/blogging/"},{"name":"vuejs","slug":"vuejs","permalink":"https://anthonyison.com/tags/vuejs/"}]},{"title":"Blogging for consistency","slug":"blogging-for-consistency","date":"2019-06-17T01:25:27.000Z","updated":"2019-07-25T12:36:40.852Z","comments":true,"path":"blogging-for-consistency/","link":"","permalink":"https://anthonyison.com/blogging-for-consistency/","excerpt":"I’ve written a few blog posts now and I try to get feedback each time. The feedback has been great and helps me to improve. I’m building up a list of things to think about as I’m writing. In this blog, I want to focus on the feedback and highlight some of the small things that are really the big thi","text":"I’ve written a few blog posts now and I try to get feedback each time. The feedback has been great and helps me to improve. I’m building up a list of things to think about as I’m writing. In this blog, I want to focus on the feedback and highlight some of the small things that are really the big things. QualityIt might seem like I should start with content, but I’ve found the experience of your reader has little to do with the content of the blog. I mean, yes, content IS important, but there are things that will lose you readers before they have even started getting into your content. Fix the broken bitsIf there is something that doesn’t work, and you know it doesn’t work, fix it. This might seem obvious, but I have overlooked it a couple of times now. It’s just embarrassing to ask for feedback and be given a list of things that you already know aren’t up to scratch. Meet expectationsThere is a baseline for features that you need to consider on your blog. Comments (give your readers a place to interact with you and your content) RSS Email subscription Links to easily share posts on social media SEO - Your readers deserve to find you. Consistency: Make a checklistOf course, you should have your own checklist. Here’s some of the things I have been getting feedback on: Filenames should be highlighted Specify your code block types (hint: html is markup and command line is bash) When writing command line code blocks, begin each command with $ and split across lines for long statements. Identify the line break with \\. If adding a comment, use #. Make sure your posts have an introduction and summary. Think about your titles. You will have them for a long time. I don’t like clickbait, but you should still try to get people to click. (So.. Cloudflare… is a good example of a bad title) ContentFinally! It’s time to talk about content and yes, content is important. But it’s also not. Of all of the advice I’ve been given on content, the common theme seems to be to write about something you are actually interested in. If you’re interested in what you’re writing about, it will show in your writing. People will FEEL it when they read your blog. This ties back into the experience of your readers. Even if I don’t understand or am uninterested in a particular topic, I may still read if the writing style takes me on a ride; if I can be put in the shoes of the writer. Convince your readers that you are invested and they will invest as well. Do you already have a checklist that you go through before posting? What else do you find important in a blog?","categories":[],"tags":[{"name":"blogging","slug":"blogging","permalink":"https://anthonyison.com/tags/blogging/"}]},{"title":"Kubernetes: AKS and Windows Containers","slug":"kubernetes-aks-and-windows-containers","date":"2019-06-10T04:52:07.000Z","updated":"2019-07-25T12:40:43.594Z","comments":true,"path":"kubernetes-aks-and-windows-containers/","link":"","permalink":"https://anthonyison.com/kubernetes-aks-and-windows-containers/","excerpt":"When I first heard about Windows containers, I got really excited by the idea of packaging ASP.Net legacy apps and ASP.Net Core apps consistently, without the need to remote into a VM and apply extra libraries. I soon found that Windows containers were quickly followed by a “yeah, but”. Windows node","text":"When I first heard about Windows containers, I got really excited by the idea of packaging ASP.Net legacy apps and ASP.Net Core apps consistently, without the need to remote into a VM and apply extra libraries. I soon found that Windows containers were quickly followed by a “yeah, but”. Windows node support has recently been added to Kubernetes and AKS. I don’t think it’s quite ready for production, but it sure does look promising. Why use Windows Containers?Firstly, we need to realise that Windows ain’t Windows. There are 2 types of windows containers: Windows Server Core Nano Server Windows Server CoreWindows Server Core is mostly your standard Windows Server. If you’re running .Net Framework services, you’re looking here. Unfortunately, the containers are HUGE! (12 gig 5 gig for a container) That said, it’s come a long way in the last few years. Overall, I like Windows Server Core because it allows legacy .Net Framework applications to be packaged and deployed in modern ways and these are the applications that usually really need it. Nano ServerNano Server solves the bloat problem with the Windows containers, coming in at a more respectable 300-ish megs, which is really exciting! “Yeah, but” it doesn’t support .Net framework. SO it’s pretty much for .Net Core projects. The problem with this is .Net Core projects really SHOULD target Linux instead. There are use cases for Nano Server, such as combining .Net Framework and .Net Core projects together on a single windows server. So, if you absolutely MUST run on Windows, Nano server has your back, though I would consider this a last resort option. The problem with Windows containersI’ve already said that I don’t think Windows containers are quite ready for production. This is mostly due to Windows container compatibility. Without Hyper-V, which is not yet supported in Kubernetes, a windows container will only run on a matching host OS version. This means your host OS and container OS needs to be matched (which isn’t too bad, I guess), but it also means they should be upgraded at the same time. ie. Upgrade the Windows OS on your nodes and watch your current services fail to start. Use them anywayTo be honest, I’m inclined to start using Windows containers anyway. Windows Server 2019 is out. Hyper-V is coming to Kubernetes. I’m expecting Microsoft to have a migration path available soon. Realistically, it will be a while before the Host OS is upgrading and I’m expecting these issues to be solved by then. Either way, I think it’s close enough that I’m prepared to look a lot closer, perhaps even as far as a staging environment. Create a Cluster in AKSNOTE: Do the following to enable the preview features required for multiple nodepools. $ az extension add --name aks-preview $ az feature register \\ --name MultiAgentpoolPreview \\ --namespace Microsoft.ContainerService $ az feature register \\ --name VMSSPreview \\ --namespace Microsoft.ContainerService It takes some time to register the features. Check the progress with: $ az feature list \\ -o table \\ --query \"[?contains(name, 'Microsoft.ContainerService/VMSSPreview')].{Name:name,State:properties.state}\" Create the cluster:In order to use multiple nodepools, we need to enable VM Scale Sets (VMSS), so make sure you do that whether you create from command line or through portal. NOTE: Password must be min 12 chars, and have Uppercase, Lowercase, numeric and Special chars $ az aks create \\ --resource-group myResourceGroup \\ --name myAKSCluster \\ --node-count 1 \\ --node-vm-size Standard_B2s \\ --enable-addons monitoring \\ --kubernetes-version 1.14.0 \\ --generate-ssh-keys \\ --windows-admin-password $PASSWORD_WIN \\ --windows-admin-username azureuser \\ --enable-vmss \\ --network-plugin azure Create Windows nodepoolNext add the Windows node pool with the following: $ az aks nodepool add \\ --resource-group myResourceGroup \\ --cluster-name myAKSCluster \\ --os-type Windows \\ --name npwin \\ --node-count 1 \\ --node-vm-size Standard_B2s \\ --kubernetes-version 1.14.0 Windows PodsI’m assuming you have connected your cluster to your kubectl, so now let’s create a Pod. Of course, normally you would create a pod with a Deployment object, but we’re just testing things out. --- apiVersion: v1 kind: Pod metadata: name: basiccorewin-pod labels: app: basiccorewin spec: containers: - name: basiccorewin image: isonaj/basiccorewin:1803 ports: - containerPort: 80 nodeSelector: beta.kubernetes.io/os: windows My Windows Pod won’t startThe Windows pod has been created and applied, but it won’t start correctly. Instead, kubectl get pods is showing the pod in a RunContainerError state. Have a closer look by running kubectl describe pod &lt;podName&gt;. You’re looking for ‘Failed to start container’ and the error message following. If it is ‘The container operating system does not match the host operating system’ then you have a Host OS/Container OS version mismatch. The container operating system does not match the host operating system. So, I ran kubectl describe node &lt;nodepool&gt; and saw that my host OS is 10.0.17763.379 (which is 1809). For the container, run docker inspect isonaj/basiccorewin:1803 and look for OsVersion. This shows my container OS version to be 10.0.17134.766 (which is version 1803). To resolve this situation, I built a new container with an OS that matches the host I want to run on. (1809) Node TaintsBefore I finish up, I should really point out Node Taints. Any way you slice it, Kubernetes really expects to be running Linux under the hood and it’s not possible to update ALL of the deployment yamls to specify the os-type. So how do we wrangle this split os-type monster? Taints are built for this purpose. The idea is that we tell Kubernetes not to run pods on the windows nodepool, unless we explicitly permit it. $ kubectl get nodes NAME STATUS ROLES AGE VERSION aks-nodepool1-16426533-vmss000000 Ready agent 3h16m v1.14.0 akswin000000 Ready agent 3h5m v1.14.0 $ kubectl taint node akswin000000 sku=win:NoSchedule node/akswin000000 tainted And done. Now if you want to run a Pod on the windows node, you need to apply a Toleration to the node, like so: --- apiVersion: v1 kind: Pod metadata: name: basiccorewin-pod labels: app: basiccorewin spec: containers: - name: basiccorewin image: isonaj/basiccorewin ports: - containerPort: 80 nodeSelector: beta.kubernetes.io/os: windows tolerations: - key: \"sku\" operator: \"Equal\" value: \"win\" effect: \"NoSchedule\" SummaryI don’t think Windows containers are quite production ready, but I think they’re getting pretty close to what I need. If you can match the container versions to the version of the host they will be deployed to, they seem to run quite happily. I think it’s worth getting used to putting .Net Framework applications into containers and even hosting in staging. I don’t think it will be long before they’re ready for production.","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://anthonyison.com/tags/kubernetes/"}]},{"title":"Kubernetes: A Beginner's Guide","slug":"kubernetes-a-beginners-guide","date":"2019-06-04T12:45:13.000Z","updated":"2019-07-25T12:37:35.457Z","comments":true,"path":"kubernetes-a-beginners-guide/","link":"","permalink":"https://anthonyison.com/kubernetes-a-beginners-guide/","excerpt":"Kubernetes is a container orchestration platform and has been described as “the OS of the cloud”. It builds on container-based services by providing many features such as volumes for stateful services, resilience and scaling, monitoring, automated zero-downtime upgrades. It runs on a cluster of node","text":"Kubernetes is a container orchestration platform and has been described as “the OS of the cloud”. It builds on container-based services by providing many features such as volumes for stateful services, resilience and scaling, monitoring, automated zero-downtime upgrades. It runs on a cluster of nodes (VMs) and allocates services to nodes based on either hard limits (eg. my service must run on linux) and prioritised preferences (eg. put these two services on the same VM). If you are running your services in containers, Kubernetes will likely make your life easier. ContainersThe first important step is to ensure your software is running in a container. A container is a way of packaging your service, along with any dependencies, removing the reliance of specific libraries, etc existing on the OS. I’m mostly assuming you know what a container is, what the benefits are and how to run one in this blog post. First stepsAssuming you have a container already (and if you haven’t you can just use one of mine to follow along), the first step is to create your cluster. Sorry, that part is up to you. Come back here when you’re done. You can take a look at this page for assistance with Azure. PodsPods are the basic building blocks of a Kubernetes system and it’s probably fair to say everything else supports Pods in keeping their services running and available. A Pod runs one or more containers and defines ports, volumes, config settings, etc to expose a container service. To create a pod, you will need a yaml file that defines its structure. If you’re not sure what yaml is, it’s like a json file with way fewer characters. It uses file layout to express relationships between properties, so take care of those spaces! Anyway, here’s our first yaml file: --- apiVersion: v1 kind: Pod metadata: name: basiccore-pod labels: app: basiccore spec: containers: - name: basiccore image: isonaj/basiccore ports: - containerPort: 80 nodeSelector: beta.kubernetes.io/os: linux Alright, that is not terribly clear because it’s got ‘basiccore’ all over it. This yaml file has 4 parts to it: apiVersion, kind, metadata and spec. We are asking for a Pod kind of component, from v1 of the API. The metadata says that the name of the pod should be basiccore-pod and it should have one label called app with the value basiccore. Inside this pod, I want a single container running image isonaj/basiccore (with port 80 exposed) and the container should be called basiccore. The nodeSelector part is just to ensure that the linux container runs on a Linux node. (with AKS supporting windows nodepools, it helps to be sure) Now, run that on the cluster using kubectl apply -f pod.yaml. You can check what is happening by running kubectl get pods. If it shows an error, use kubectl describe pod basiccore-pod to find out more. Once you’re finished, there’s nothing more to see. We won’t actually be using this to go further. Nobody expects the spanish inquision and nobody starts a pod on its own. Delete your pod with kubectl delete pod basiccore-pod. DeploymentsSo let’s start over. Nobody starts a pod by itself, because there’s a much better construct for running pods and that is a Deployment. A deployment will provide zero downtime by managing all sorts of things for you. It can be used to automatically rollout new image versions or pod configs (basically anything that could put your uptime at risk). We’ll take a closer look in a later post. Let’s jump into the yaml: --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: basiccore-deployment spec: replicas: 2 template: metadata: name: basiccore-pod labels: app: basiccore spec: containers: - name: basiccore image: isonaj/basiccore ports: - containerPort: 80 nodeSelector: beta.kubernetes.io/os: linux It’s a bit bigger than the Pod yaml. Let’s work through from the top. Deployments weren’t available in v1. It was added in extensions/v1beta1. Next, we’re creating a Deployment, not a Pod and giving it a name of basiccore-deployment. The spec for a deployment consists of the number of replicas and the template. We are starting 2 Pods with this one and the template is the yaml we used to create the Pod earlier. Let’s take a look: $ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE basiccore-deployment 2/2 2 2 33s $ kubectl get pods NAME READY STATUS RESTARTS AGE basiccore-deployment-c46759d6d-5qw96 1/1 Running 0 7s basiccore-deployment-c46759d6d-f94lk 1/1 Running 0 7s ServicesWe’ve just spent all of this time starting and stopping pods, but we haven’t actually connected to it yet. We need a way to get in, and get directed to the pod. For this, we use a Service component. A Kubernetes Service is an abstraction layer which defines a logical set of Pods and enables external traffic exposure, load balancing and service discovery for those Pods. - kubernetes.io What’s that mean? A service component is basically a load balancer that sits across some pods and directs the incoming requests where they are supposed to go. --- apiVersion: v1 kind: Service metadata: name: basiccore-service spec: type: LoadBalancer selector: app: basiccore ports: - protocol: TCP port: 80 targetPort: 80 This service will open up a port in our cluster and load balance any traffic across the pods in the selector. In this case, we’re creating a service with a type of LoadBalancer targetting any pod with the metadata app of basiccore (which we applied in the deployment template). Run kubectl apply -f basiccore-service.yaml to apply the service and then kubectl get services to see the current state. $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE basiccore-service LoadBalancer 10.0.55.65 &lt;pending> 80:30376/TCP 5m52s $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE basiccore-service LoadBalancer 10.0.55.65 13.75.220.78 80:30376/TCP 8m12s Once the External IP is displayed, put that into your browser, and there it is. A container, in a pod, accessible from the outside world.","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://anthonyison.com/tags/kubernetes/"}]},{"title":"Kubernetes: Setting up a cluster on AKS","slug":"kubernetes-setting-up-a-cluster-on-aks","date":"2019-06-04T12:45:12.000Z","updated":"2019-07-25T12:40:43.594Z","comments":true,"path":"kubernetes-setting-up-a-cluster-on-aks/","link":"","permalink":"https://anthonyison.com/kubernetes-setting-up-a-cluster-on-aks/","excerpt":"Most cloud providers provide a managed Kubernetes cluster at this point. Each time I come back to look at Kubernetes, I feel like I’ve forgotten something (or everything). This post is a cheat sheet for getting a cluster up and running on Azure (using AKS) with recommended extras. Creating a Clust","text":"Most cloud providers provide a managed Kubernetes cluster at this point. Each time I come back to look at Kubernetes, I feel like I’ve forgotten something (or everything). This post is a cheat sheet for getting a cluster up and running on Azure (using AKS) with recommended extras. Creating a ClusterGetting readyFirstly, let’s install the latest Azure CLI. Check here for the latest version. Run az --version to see what version you have if you have it installed already. Next, az login and az account set -s &lt;subscriptionId&gt; so that you’re ready to go. Create the resource group: (location is important. some areas have no AKS support yet eg. australiasoutheast) $ az group create --name myResourceGroup --location australiaeast Create a Linux-only clusterCreate the AKS cluster: $az aks create \\ --resource-group myResourceGroup \\ --name myAKSCluster \\ --node-count 1 \\ --enable-addons monitoring \\ --generate-ssh-keys Connect kubectl to your clusterInstall latest kubectl using az aks install-cli. (You may need to update your path to find the correct kubectl.exe) $ az aks get-credentials --resource-group myResourceGroup --name myAKSCluster Connect to the Kubernetes Dashboard: $ az aks browse --resource-group myResourceGroup --name myAKSCluster If you get permissions errors (due to RBAC), you can give cluster-admin permissions with: $ kubectl create clusterrolebinding kubernetes-dashboard \\ -n kube-system --clusterrole=cluster-admin \\ --serviceaccount=kube-system:kubernetes-dashboard","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://anthonyison.com/tags/kubernetes/"}]},{"title":"Serverless what? Why do we need it?","slug":"serverless-what-why-do-we-need-it","date":"2019-05-19T22:58:24.000Z","updated":"2019-07-25T12:40:43.595Z","comments":true,"path":"serverless-what-why-do-we-need-it/","link":"","permalink":"https://anthonyison.com/serverless-what-why-do-we-need-it/","excerpt":"“Serverless” was one of those terms that left me scratching my head when I first heard it. How on earth do you run a server… without a server??? That’s some crazy marketing spin! What I quickly learned is that serverless is referring to how much infrastructure you need to manage. That is, none. Nada","text":"“Serverless” was one of those terms that left me scratching my head when I first heard it. How on earth do you run a server… without a server??? That’s some crazy marketing spin! What I quickly learned is that serverless is referring to how much infrastructure you need to manage. That is, none. Nada. So who cares? I mean, I’m running on PaaS. I can change the number of servers with a slider, or set rules to automatically add and remove servers as my traffic changes. Isn’t that good enough? Not according to Troy Hunt. When your traffic spikes (like, when your site is on the news and a million people pick up their phone at the same time and hit your site), you can go from “too much cloud” to “not enough cloud” very quickly. It’s in this environment of rapidly changing traffic (and realistically, that’s when it counts), that serverless really shines. So what is it?Alright, so what IS serverless? Let’s consider what you might be using now. You’ve got a few VMs on a scale set, or you’ve got a few VMs as nodes of a Kubernetes cluster, or maybe you have some PaaS offering where you pick the number of machines backing it. You’ve got some rules in place to scale up as traffic increases and then back down to reduce costs when it falls again. Each of these scenarios have: a fixed monthly costs per backing VM a maximum traffic threshold increasing latency as the traffic approaches the threshold rules to increase and decrease the number of backing VMs to trade off running cost vs latency Let’s say you increase your VMs by 10x or 100x. Assuming your architecture can scale, your latency issues have just vanished. Your servers are idling with unlimited resources compared to the current load. HOWEVER, your running costs have also increased by 10x or 100x. But the servers are just idling. So, what if you only paid for the activity you caused? That fraction of a ms of CPU. That couple of KB of RAM as you process an incoming request. Assuming the price is right, wouldn’t that be better? Assuming the costs are around VM rate * Utilisation, you’re instantly ahead! No more scaling of resources. Costs are directly related to resources used. Oh, and one final thing. The available resources is now a DATACENTER worth of resources. Your armageddon-style traffic spike is barely a blip on their radar. That is Serverless. How do I use it?Unfortunately, serverless doesn’t necessarily come for free. Architecturally, you don’t run your server any more. And I mean software server, not the VM. Instead, you need to present a function based API (eg. Azure Functions or AWS Lambda) and that is effectively injected into the provider’s service to execute as configured. If you have followed a Clean Code Architecture, it’s probably simple to extract your application logic into a Functions application. If you’ve got application code in your controllers, or using Filters, etc, well, that will take more. Some services are Serverless already and some are not. If you want to build serverless, you’re looking at: Storage Azure Functions Service Bus SignalR service AKS (with virtual kubelet) If you want to bring your serverless architecture to its knees, try: SQL Server (for now - serverless is coming) Web apps I’ve had a hard time putting AKS in either bucket at the moment. It runs on specific nodes (so not serverless), but there’s also a virtual Kubelet that lets you use ACI as a serverless overflow. Personally, I prefer the Azure Function pricing model over the ACI pricing model and the cost of spinning up a function is MUCH lower than spinning up a container, however it might keep up if your site had a massive traffic spike. Probably somewhere between “pure” serverless and PaaS, but this is just a guess. So, it may be possible to use containers, AKS and Virtual Kubelet to take you some of the way towards stability within rapid traffic spikes, depending on your service startup time. Final wordsServerless brings an extraordinary level of burst tolerance to your application, which will bring resilience and performance under extreme loads. As with any architectural decision, it’s not all or nothing. You can have parts of a system that are serverless, with other parts not, such as a Web App that sends messages to a Service Bus. With a serverless backing, the web app will likely provide greater resilience under load. Use load testing to measure where your bottlenecks are. Importantly, look for any part of your architecture where serverless is hitting resource bound components. Make sure you have a fallback strategy for when the resource bound component is at maximum load. Serverless is actually not a new idea and there are many serverless services available. Please refer to the Azure Serverless services for more info. Effective use of serverless components in your architecture will massively increase the scalability of your application.","categories":[],"tags":[{"name":"serverless","slug":"serverless","permalink":"https://anthonyison.com/tags/serverless/"}]},{"title":"So... Cloudflare...","slug":"so-cloudflare","date":"2019-05-05T10:40:42.000Z","updated":"2019-07-07T10:35:48.544Z","comments":true,"path":"so-cloudflare/","link":"","permalink":"https://anthonyison.com/so-cloudflare/","excerpt":"I went to a great talk by Troy Hunt in Brisbane a while ago. Well, it was great at the time. It didn’t take long before I started to realise that most of the struggles I’ve had with HTTPS on my blog could have actually been side stepped quite nicely by using Cloudflare. Let me be clear. This wasn’t","text":"I went to a great talk by Troy Hunt in Brisbane a while ago. Well, it was great at the time. It didn’t take long before I started to realise that most of the struggles I’ve had with HTTPS on my blog could have actually been side stepped quite nicely by using Cloudflare. Let me be clear. This wasn’t the first time I heard of Cloudflare. To be honest, I didn’t actually know what it was before now though, and Troy has a way of presenting things so that they seem really quite simple. Cloudflare seems to provide a service that just puts a bow on hosted services: Free SSL, CDN/caching, DNS, traffic management. Cloudflare aim to have an edge within 10ms of every client on the planet. Since I already had my HTTPS sorted, I didn’t worry too much about it at the time. Now, I’m looking for CDN and it wouldn’t hurt to have an overlay on my site that allows some modifications to requests and responses (like HTTP/2, which Cloudflare seem to enable by default). Getting set up is easy enough. Create an account with Cloudflare. Add a site (eg. anthonyison.com). Set up the DNS servers with your domain provider. Add an A record to cloudflare to point to your IP (eg. for AKS) or CNAME to redirect to your alternate domain (eg. GitHub pages or web app) Wait for the change to take effect. This can take up to 48 hours. Once CDN is in place, we’ve got one small problem. When we change the content, we need to be able to purge the cache. Cloudflare provides an API for achieving this. We just need to add it to the build pipeline. One way of doing it would be to create a Logic App that punches the API whenever there’s a new commit on the github pages repo. I might do that later on… For now, I’ve hosted both blogs, just for comparison. I’m running Lighthouse against both to see if there’s much of a difference. Running Ghost: Running Hexo on Github Pages: Running Hexo on Github Pages behind Cloudflare: With Cloudflare in place, I have CDN, HTTPS, HTTP/2 in place. I’ve enable Rocket Loader to improve paint time and auto-minify so that I can pull that from my build process. I can enable HSTS automatically, but not sure it’s necessary? For now, I think the numbers are heading in the right direction, even though I seem to have introduced a couple of new issues while migrating to hexo.","categories":[],"tags":[{"name":"CDN","slug":"cdn","permalink":"https://anthonyison.com/tags/cdn/"}]},{"title":"Migrating from Ghost to Hexo","slug":"migrating-from-ghost-to-hexo","date":"2019-05-04T13:12:56.000Z","updated":"2019-07-07T10:34:24.599Z","comments":true,"path":"migrating-from-ghost-to-hexo/","link":"","permalink":"https://anthonyison.com/migrating-from-ghost-to-hexo/","excerpt":"It was surprisingly easy to migrate my blog out of ghost, but there were a few missed steps along the way. Often, I would find a better way after I had done the heavy lifting. 1. Install Hexo and create the blog $ npm install hexo-cli -g $ hexo init myblog $ cd myblog 2. Install the hexo-casper t","text":"It was surprisingly easy to migrate my blog out of ghost, but there were a few missed steps along the way. Often, I would find a better way after I had done the heavy lifting. 1. Install Hexo and create the blog$ npm install hexo-cli -g $ hexo init myblog $ cd myblog 2. Install the hexo-casper theme$ git clone https://github.com/xzhih/hexo-theme-casper.git themes/hexo-casper 3. Configure the theme and siteEdit _config.yaml # Site title: Anthony Ison subtitle: Software development and DevOps. Bringing solutions to life. description: My meandering thoughts on development, devops and technology keywords: software development,devops,azure,kubernetes,angular,serverless,docker author: Anthony Ison language: en timezone: Australia/Brisbane # From http://momentjs.com/timezone/ url: http://anthonyison.com root: / # Set these to create lowercase, title-only permalinks (like ghost) permalink: :title/ filename_case: 1 # consider creating a folder with each post to hold any assets post_asset_folder: true Edit themes/hexo-casper/_config.yaml 4. Migrate posts from ghost to hexoIn Ghost:Labs &gt; Export content $ npm install hexo-migrator-ghost --save $ hexo migrate ghost my-ghost.json FAILED! $ npm install hexo-migrator-tryghost --save $ hexo migrate ghost my-ghost.json FAILED! These probably failed because I was running Ghost 2.x and the export format has changed. If you’ve got an earlier version, maybe this will work for you. $ docker run -it -v $(pwd):/temp golang $ go get -v github.com/jqs7/ghost-hexo-migrator $ cd /temp $ ghost-hexo-migrator my-ghost.json FAILED! This got a little closer, and actually pulled content across, but now I’m out of options. Fortunately, I don’t have many posts and will manually migrate instead. I hope you have better luck. 5. Reattach the post imagesMany of the migration tools will bring content across without images. So afterwards, you will need to copy the images in and link them to posts manually. Also, it’s worth configuring an image optimizer, using: $ npm i hexo-filter-responsive-images --save Then add to the _config.yaml: # hexo-filter-responsive-images responsive_images: pattern: '**/*.+(png|jpg|jpeg)' sizes: small: width: 800 withoutEnlargement: true large: width: 2000 withoutEnlargement: true To each of the blog post headers, add: image: my-blog-post/small_cover.jpg feature_img: large_cover.jpg where cover.jpg is the original image for the post cover. 6. Configure RSS$ npm install hexo-generator-feed --save Add this to your _config.yaml: feed: type: atom path: atom.xml limit: 20 hub: content: content_limit: 140 content_limit_delim: ' ' order_by: -date icon: icon.png 7. Configure deploy$ npm install hexo-deployer-git --save Edit _config.yaml deploy: type: git repo: https://github.com/isonaj/isonaj.github.io.git branch: master","categories":[],"tags":[{"name":"ghost","slug":"ghost","permalink":"https://anthonyison.com/tags/ghost/"},{"name":"blogging","slug":"blogging","permalink":"https://anthonyison.com/tags/blogging/"},{"name":"hexo","slug":"hexo","permalink":"https://anthonyison.com/tags/hexo/"}]},{"title":"Serverless markdown blogs with Hexo","slug":"serverless-markdown-blogs-with-hexo","date":"2019-05-03T11:27:32.000Z","updated":"2019-07-25T12:40:43.595Z","comments":true,"path":"serverless-markdown-blogs-with-hexo/","link":"","permalink":"https://anthonyison.com/serverless-markdown-blogs-with-hexo/","excerpt":"Let me start this by saying I’m loving my ghost blog, and I get a kick out of running it on AKS. The thing is, the content only changes when I post and so I’m thinking about caching and I realise the whole blog can be cached. It’s not an API. I don’t have changing data. (Ok, TECHNICALLY I have a db,","text":"Let me start this by saying I’m loving my ghost blog, and I get a kick out of running it on AKS. The thing is, the content only changes when I post and so I’m thinking about caching and I realise the whole blog can be cached. It’s not an API. I don’t have changing data. (Ok, TECHNICALLY I have a db, but bear with me) My posts are markdown, and I could just store them in git and publish static pages when I push. After some searching, I have found there are many static web site generators. The ones that stood out for me were: Jekyll - this is number 1 and the default in Github Pages. It runs on Ruby. Hexo - this is huge in China and built on node Vuepress - built for Vue docs. I think I will love this when the project is a bit more mature. I thought I’d review Jekyll and Hexo, so I pulled a jekyll container in one window and installed Hexo in another. Unfortunately, I was up and running with Hexo before my download even finished, so rather than having a post that contrasts the two, I seem to have already chosen Hexo. JekyllThis is far and away the most popular. It has a thiving community and is well supported by Github Pages. The main disadvantage is that it becomes exponentially slower as pages are added, which wouldn’t likely be an issue for my blog but is worth noting. HexoHexo is number 2 in popularity (mostly in China) and is growing fast. It also has many themes, and most of the demo sites are in Chinese. Installing HexoSince it’s built on node, Hexo is super easy to install (assuming you already have node installed!) We will be using npm to install. # Install Hexo: $ npm install hexo-cli -g # Create a site: $ hexo init my-site # Create a post: $ hexo new post \"This is going to be a great post\" # Serve your site locally: $ hexo serve # Generate the static site: $ hexo generate You can also: Create a draft with hexo new draft &quot;This is a draft post&quot; Publish a draft with hexo publish post this-is-a-draft-post Deploy your site: hexo deploy ThemesThere are many themes around. Usually, you pull a git repo into your themes/theme-name folder. Themes basically wrap the whole presentation process, which means each theme has specific capabilities. (eg. some have google analytics, some have disqus comments). If you want to mix and match, you quickly find yourself editing your theme. PluginsThere are different types of plugins. They seem to hook into the build process and provide various services. I haven’t looked into them too much yet. MigratorsThere are migrators available and you can pull them in with npm install. I quickly found migrators for Wordpress and Ghost blogs. SummaryHexo is node-based and provides a familiar interface for an Angular developer. It is a fantasic tool for getting a blog up and running and has capability to migrate from existing platforms. Since it is git based, it’s a bit harder to manage from my phone, however I LOVE that my markdown content is in git so I can review changes and I know it won’t be lost in a corrupt database. What do you think? Would you use Hexo?","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://anthonyison.com/tags/hexo/"}]},{"title":"Dynamic environment in your static Angular application","slug":"dynamic-environment-in-your-static-angular-application","date":"2019-04-24T14:00:00.000Z","updated":"2019-07-07T10:33:09.290Z","comments":true,"path":"dynamic-environment-in-your-static-angular-application/","link":"","permalink":"https://anthonyison.com/dynamic-environment-in-your-static-angular-application/","excerpt":"I keep hitting the same problem when building Angular applications. Environment settings! They are easy to set up in development, but as you target different environments, the old “one file per environment” really doesn’t cut it. I don’t want to rebuild my application just to deploy to production an","text":"I keep hitting the same problem when building Angular applications. Environment settings! They are easy to set up in development, but as you target different environments, the old “one file per environment” really doesn’t cut it. I don’t want to rebuild my application just to deploy to production and if it’s in a container? Pfft, good luck! I’ve solved this problem a few different ways in the past and I’ve just solved it again. But this time, it didn’t feel quite so hacky, so I thought I’d post about it. ProblemAngular CLI provides an environment.ts for storing your global settings and you can select which environment file to use when you build. I want to build my application once and then deploy to different environments without rebuilding, however I can’t change my environment settings on deploy or through environment variables. There are a few reasons I don’t want to rebuild. I want to test in staging and then redeploy the artifact to production I want to run it from a container SolutionOk, so this is not a new problem and it has been reasonably solved on server side deployments a few ways: Environment variables / web.config / appsettings.json - config is easily overridden in place and is often used for server config settings. Rewrite on deploy - the deployment script itself can overwrite settings as it is deployed to configure the environment it is deploying to. Option 1: Inject bootstrap settings into the index.htmlThis was my first attempt at solving the problem. I added a comment in the index.html and created an MVC endpoint to load the index.html file, replace the comment with a script block to create a settings object and return the updated html page. It was good for keeping the number of requests down, but it felt a bit hacky. Option 2: A separate bootstrap script fileThis approach was inspired by this post. The basic idea is to pull a separate self-executing script that contains our bootstrap settings from the index.html. &lt;!doctype html> &lt;html lang=\"en\"> &lt;head> &lt;meta charset=\"utf-8\"> &lt;title>My Awesome Angular app&lt;/title> &lt;base href=\"/\"> &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"> &lt;!-- Load environment variables --> &lt;script src=\"assets/bootstrap.js\">&lt;/script> &lt;/head> &lt;body> &lt;app-root>&lt;/app-root> &lt;/body> &lt;/html> Next, create the bootstrap.js file in your assets folder. It should look something like this: (function (window) { window.bootstrapSettings = { apiUrl: 'https://localhost:44384', production: false, }; }(this)); When the angular app loads, we now have a bootstrap object available to pull settings from. In this case, I can reference window.bootstrapSettings.apiUrl to find my api location, but I’m trying to use environment.apiUrl. Next, we need to update environment.ts to bring in the bootstrap settings. export const environment = Object.assign({ production: false, }, (window as any).bootstrapSettings); At this point, we can build once and serve from different static sites by simply applying a different assets/bootstrap.js file with the new settings during deployment. This is good, but we’re serving from dotnet core, so we can do better. (If you’re using node, the idea is not much different). The basic idea is to avoid serving the static bootstrap file and instead, send a bootstrap file based on our appsettings file, which we can easily override from our environment (web app, container, etc) using the middleware below. public class EnvironmentBootstrap { public string apiUrl { get; set; } } public static class EnvironmentBootstrapExtensions { public static IApplicationBuilder UseEnvironmentBootstrap( this IApplicationBuilder builder, string path) { return builder.UseMiddleware&lt;EnvironmentBootstrapMiddleware>(path); } } public class EnvironmentBootstrapMiddleware { private readonly RequestDelegate _next; private readonly EnvironmentBootstrap _environment; private readonly string _endpointPath; public EnvironmentBootstrapMiddleware( RequestDelegate next, IOptions&lt;EnvironmentBootstrap> options, string path) { _next = next; _endpointPath = path; _environment = options.Value; } public async Task Invoke(HttpContext httpContext) { // Short circuit on request for bootstrap.js if (httpContext.Request.Path .Equals(_endpointPath, StringComparison.Ordinal)) { httpContext.Response.ContentType = \"application/javascript\"; await httpContext.Response.WriteAsync( \"(function (window) { window.bootstrapSettings = \" + JsonConvert.SerializeObject(_environment) + \";}(this));\"); } else // Pass to next item in the pipeline await _next.Invoke(httpContext); } } Finally, activate the pipeline in the Startup.cs file: public class Startup { public void ConfigureServices(IServiceCollection services) { // ... services.Configure&lt;EnvironmentBootstrap>( Configuration.GetSection(\"client\")); // ... } public void Configure(IApplicationBuilder app) { // ... // Bootstrap the bootstrap.js file ahead of UseStaticFiles app.UseEnvironmentBootstrap(\"/assets/bootstrap.js\"); app.UseStaticFiles(); app.UseSpaStaticFiles(); // ... } } That’s it! The project can now be built once and deployed to different environments, with angular client environment settings available to be configured from the environment itself. For an Azure Web app, set an Application Setting ‘client:apiUrl’ to override the client’s apiUrl environment setting. What do you think? Is there a better solution? What do you like or dislike about this approach?","categories":[],"tags":[{"name":"dotnet","slug":"dotnet","permalink":"https://anthonyison.com/tags/dotnet/"},{"name":"angular","slug":"angular","permalink":"https://anthonyison.com/tags/angular/"}]},{"title":"Automatic HTTPS on Kubernetes","slug":"automatic-https-on-kubernetes","date":"2019-02-16T14:00:00.000Z","updated":"2019-07-07T10:32:08.344Z","comments":true,"path":"automatic-https-on-kubernetes/","link":"","permalink":"https://anthonyison.com/automatic-https-on-kubernetes/","excerpt":"This post starts with a slight regret that I didn’t get Ghost running on a Web App. One of the brilliant parts of a Web App is that you can force all requests over HTTPS with the click of a button. Of course, I’d still need to organise a certificate for my domain. Hold on, let me stop and back up a","text":"This post starts with a slight regret that I didn’t get Ghost running on a Web App. One of the brilliant parts of a Web App is that you can force all requests over HTTPS with the click of a button. Of course, I’d still need to organise a certificate for my domain. Hold on, let me stop and back up a minute. What the heck is this HTTPS and certificate stuff? Basically, HTTPS will guarantee that the communication between the client and server can’t be read or changed by anyone between the client and server. So, usernames and passwords are safe to send. While that’s important, it’s probably more important that your pages cannot be changed either. It’s a bit like a message written in code with the king’s seal. Since the code (HTTPS) is known to you and the king, you know it cannot be read. The seal (certificate) proves the authenticity. As I set out on this adventure, it looks like I need cert-manager and the best way to install this appears to be to use helm, which I installed with Chocolatey. $ choco install kubernetes-helm $ helm init First stepsWe are going to install cert-manager which will perform all of the magic of fetching certificates and storing them for use in our various services. We need to set up the config for cert-manager, so that we can provide the link to Lets Encrypt. Save the following in a file, say issuer.yaml, and run kubectl apply -f issuer.yaml to apply. (Make sure you update with your email first!) apiVersion: certmanager.k8s.io/v1alpha1 kind: ClusterIssuer metadata: name: letsencrypt-prod spec: acme: server: https://acme-v02.api.letsencrypt.org/directory email: youremail@gmail.com privateKeySecretRef: name: letsencrypt-prod http01: {} Installing cert manager$ kubectl apply -f \\ https://raw.githubusercontent.com/jetstack/cert-manager/release-0.6/deploy/manifests/00-crds.yaml $ helm install --name cert-manager --namespace ingress \\ --set ingressShim.defaultIssuerName=letsencrypt-prod --set ingressShim.defaultIssuerKind=ClusterIssuer stable/cert-manager I ran into issues installing cert-manager with a ‘cluster-admin’ not found error. I found instructions on this page which helped me create a cluster admin role, create a service account and assign tiller to it. Installing nginx-ingressThe next step is to configure an Ingress to manage the TLS endpoint, that is to manage my HTTPS endpoint with certificate connected to my domain. Without this step, I found I could set up my Ingress entry, but the address would stay empty. $ helm install stable/nginx-ingress \\ --name nginx \\ --set rbac.create=true \\ --namespace ingress Once installed, I can see a LoadBalancer entry which has my External IP on it. Update the ServiceIn the previous post, we set the service up as a LoadBalancer type. We don’t need that any more since we have a new IP on our LoadBalancer nginx-ingress service. Update the service.yaml and change LoadBalancer to a NodePort and run kubectl apply -f service.yaml. This will make sure we can only access our service through our TLS ingress service. Generate Certificate and Ingress for ServiceApply the following updates to the kubernetes cluster. apiVersion: extensions/v1beta1 kind: Ingress metadata: name: anthonyison-ingress annotations: kubernetes.io/ingress.class: nginx certmanager.k8s.io/cluster-issuer: letsencrypt-prod spec: tls: - hosts: - anthonyison.com secretName: anthonyison-crt rules: - host: anthonyison.com http: paths: - path: / backend: serviceName: anthonyison servicePort: 80 apiVersion: certmanager.k8s.io/v1alpha1 kind: Certificate metadata: name: anthonyison-crt spec: secretName: anthonyison-crt dnsNames: - anthonyison.com acme: config: - http01: ingressClass: nginx domains: - anthonyison.com issuerRef: name: letsencrypt-prod kind: ClusterIssuer That’s it! Hit your domain and confirm that https is working. You should be able to click on the padlock in the address bar and click on Certificate to see the details. You should see a certificate issued by Lets Encrypt to your domain name. So, I started off with some regret that I wasn’t running in a Web App. While it took quite a while to work through many of the issues that showed up along the way, it is actually pretty easy once it’s set up, and furthermore, I don’t have to think about my certificates ever again. I think maybe it’s not as bad as I thought. No regrets, right? References: Automated TLS with Cert Manager and Lets Encrypt for Kubernetes Get automatic HTTPS with Lets Encrpyt and Kubernetes Ingress How to use Lets Encrypt on Kubernetes (without Cert Manager) Configuring AKS Secure your Kubernetes Services using Cert Manager","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://anthonyison.com/tags/kubernetes/"}]},{"title":"Running Ghost on Kubernetes on Azure","slug":"running-ghost-on-kubernetes-on-azure","date":"2019-01-15T14:00:00.000Z","updated":"2019-07-07T10:34:42.595Z","comments":true,"path":"running-ghost-on-kubernetes-on-azure/","link":"","permalink":"https://anthonyison.com/running-ghost-on-kubernetes-on-azure/","excerpt":"In my previous post, I was looking into a few options for running my blog. I think at this time, I’m going to keep it on Azure because I can run it for free. I suspect I would make a different choice if not for my bonus credits. I will need some benchmark figures to choose a provider, however kubern","text":"In my previous post, I was looking into a few options for running my blog. I think at this time, I’m going to keep it on Azure because I can run it for free. I suspect I would make a different choice if not for my bonus credits. I will need some benchmark figures to choose a provider, however kubernetes should give me the platform I need to change in the future if necessary. I have a basic level of understanding of how kubernetes hangs together and would love to hear your feedback if you would do things differently. The basic idea is to run a ghost container and provide persistent storage for the content. In the future, I would like to use nginx to reverse proxy incoming traffic and to provide HTTPS for my site. I have used AKS to generate a kubernetes cluster and my kubectl is configured to connect to it. First, I need to configure my storage. For this, I use a yaml file. apiVersion: v1 kind: PersistentVolumeClaim metadata: name: anthonyison-content spec: accessModes: - ReadWriteOnce resources: requests: storage: 5Gi storageClassName: default Using kubectl apply -f volume.yaml we can generate the volume claim to be used in the next step. Next, we will generate a deployment for the the ghost container, linking it to the anthonyison-content volume. apiVersion: apps/v1beta1 kind: Deployment metadata: name: anthonyison labels: app: anthonyison spec: replicas: 1 selector: matchLabels: app: anthonyison template: metadata: labels: app: anthonyison spec: containers: - name: anthonyison image: ghost:2.9.1-alpine imagePullPolicy: Always ports: - containerPort: 2368 env: - name: url value: http://anthonyison.com volumeMounts: - mountPath: /var/lib/ghost/content name: content volumes: - name: content persistentVolumeClaim: claimName: anthonyison-content So now we have a ghost container running in Kubernetes with an external mounted volume for storing content. However, it’s not exposed as yet. We do that with a Service. The service.yaml is below. apiVersion: v1 kind: Service metadata: name: anthonyison spec: type: LoadBalancer selector: app: anthonyison ports: - protocol: TCP port: 80 targetPort: 2368 And that’s actually all there is to it. By running kubectl get services you can see the External IP. If you put that in the browser, you will go to the new blog. Better still, put the IP into your DNS A record, and your domain name will direct to the new site.","categories":[],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"https://anthonyison.com/tags/kubernetes/"},{"name":"ghost","slug":"ghost","permalink":"https://anthonyison.com/tags/ghost/"},{"name":"azure","slug":"azure","permalink":"https://anthonyison.com/tags/azure/"}]},{"title":"Creating a blog with Ghost","slug":"creating-a-blog-with-ghost","date":"2019-01-07T14:00:00.000Z","updated":"2019-07-07T10:36:03.633Z","comments":true,"path":"creating-a-blog-with-ghost/","link":"","permalink":"https://anthonyison.com/creating-a-blog-with-ghost/","excerpt":"There seems to come a time in a software developer’s life where you look at creating a blog. It’s that time for me. I want a place where I can write up some of my experiments for later reference, and if that can help others along the way, all the better! Considerations 1. I don’t want to pay anyth","text":"There seems to come a time in a software developer’s life where you look at creating a blog. It’s that time for me. I want a place where I can write up some of my experiments for later reference, and if that can help others along the way, all the better! Considerations I don’t want to pay anything. I really don’t want to break the bank with this project. If I can pay nothing, I will. This puts Azure squarely in the front seat because I have $70 a month to spend there. Easy to use. I don’t want to spend ages messing with this project, or debugging issues. Broad application / reusable. It would be great if this thing can be used for more than just this blog. If I can host other sites or blogs on the same infrastructure, that would be kinda handy. Preferably something I want to learn. Cause, you know. What’s the point otherwise? At first, I had thought I’d be using Wordpress and I wasn’t really looking forward to that. On the upside, there are wordpress containers around and I was pretty keen to run it in a container. After a quick email with Thiago, I started looking at Ghost. Once I knew it was there, I noticed that many of the blogs I read, including Troy Hunt, are powered by Ghost. With little more than that meagre planning, it was time to get started. Attempt 1: Azure Web appsFirstly, I needed a place to host it. I’m an Azure guy, so I started there. It seemed to be straight forward enough. A ghost container, wrapped in a Web App, running on Linux, volume mapped to a Azure File storage. I ran it locally and it worked perfectly. Once installed on Azure, I found the database just wouldn’t load up correctly, giving Migration errors, saying that the database was locked. First attempt foiled! Attempt 2: Google GKEMy next attempt was to spin it up on GKE on to Google cloud. Kubernetes seemed to be a bit of overkill for what I was trying, but Google made that super easy, and it pretty much “just worked”. That left me with the question, what about AKS on Azure? Attempt 3: Azure AKSI’ve never created an AKS cluster. I mean, I’ve wanted to. Who hasn’t? The thing is, I’ve never actually clicked the Go button. So, I guess it’s time. It was easy enough to configure as well and then I clicked Create and waited. I waited and then I waited some more. I went looking for any events showing that something was happening, but couldn’t see anything. So I tried again and this time, it worked. It spun up easy enough and with minor changes to the PersistentVolumeClaim, it just worked as well, albeit it a bit slower than GKE, which was odd because I had double the resources on Azure. So, now what?Alright, so now I seem to be on the kubernetes train. Even writing it now, it seems kinda crazy to spin up a kubernetes cluster to run a blog that is probably only going to have me as traffic. But it is expandable. There are a couple of sites I want to host. They’re currently in containers on Azure Web apps, but should move across easy enough. I’m still not sure of cost. I will run both solutions for a couple of days and have a look at what charges come through. I hadn’t planned to move from Azure at this time. That’s where I have the most experience. Next steps Run some performance and pricing measures to compare GKE vs AKS and decide where my blog will stay. Write up the technical steps for creating the blog. Enable the site to run HTTPS with Let’s Encrypt certificates.","categories":[],"tags":[{"name":"ghost","slug":"ghost","permalink":"https://anthonyison.com/tags/ghost/"}]}]}